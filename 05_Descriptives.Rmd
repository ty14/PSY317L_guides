# Descriptives

Descriptive statistics describe basic features of the data in simple summaries such as mean, median, and mode. These statistics used to present quantitative descriptions of data in graphing. You can use functions in base R and `tidyverse` to get descriptive statistics. 


```{r message=FALSE}
library(tidyverse)

atx <- read_csv("data/austin_weather.csv")

head(atx) # first 6 rows
```

Focus in the temperature column for now

```{r}
ggplot(atx, aes(x= temp)) + 
  geom_histogram(color="black", fill="lightseagreen", binwidth = 10)+
  theme_classic()
```

## Basic Descriptives
```{r}
length(atx$temp) # length this tells you the 'n'

sum(atx$temp) # sum

range(atx$temp) # range 

min(atx$temp) # minimum

max(atx$temp) # maximum

var(atx$temp) # variance 

```


## Mean, Median, and Mode 

```{r}
mean(atx$temp) # mean

sum(atx$temp)/length(atx$temp) # mean

median(atx$temp) # median

#estimate mode function 
estimate_mode <- function(x) {
  d <- density(x)
  d$x[which.max(d$y)]
}  

estimate_mode(atx$temp) # using the function to get estimate mode
```

For some descriptives, like mode, there is not a function already built into R, so a function needs to be made. The above code has a function for the estimated mode, this function works best with large data sets. 

## Standard Deviation 

``` {r}
sd(atx$temp) #  sample standard deviation

#population standard deviation function 
 pop.sd <- function(s) { 
   sqrt(sum((s - mean(s))^2)/length(s)) 
 } 

pop.sd(atx$temp) # population standard deviation with the function 
```

## Standard Error 

What about standard error?

``` {r}
length(atx$temp) # we need to know the N to calculate the SEM
sd(atx$temp) / sqrt(length(atx$temp)) #SEM by hand

sem <- function(x){sd(x) / sqrt(length(x))} # a function to get SEM

sem(atx$temp) #using the function

```

please note  - if you have missing data use this function for SEM

```{r}
sem <- function(x){sd(x,na.rm=T) / sqrt(length(na.omit(x)))}
```

## Inter-quartile Ranges 

``` {r}
quantile(atx$temp, .25)  # this is the lower quartile

quantile(atx$temp, .75)  # this is the upper quartile

IQR(atx$temp)   # this is the inter-quartile range.

```

Don't be worried if these quartiles are slightly different to what you'd get by hand.

```{r}
ggplot(atx, aes(y=temp)) + 
  geom_boxplot(color='black', fill='lightseagreen')
```

nb we get those numbers on the x-axis because there is no 'group'
we can get rid of them like this:

```{r}
ggplot(atx, aes(y=temp)) + 
  geom_boxplot(color='black', fill='lightseagreen') + 
  scale_x_discrete(breaks = NULL)
```

## Descriptives for Groups
 
Often in experiments you are looking for group differences, the following code will show you how to get descriptive statistics for each group. 

This is a time where `tidyverse` comes in handy!

First read in the data and notice it has a group column, genre. 

```{r message=FALSE}
vg <- read_csv("data/videogames.csv")

head(vg)
```

The function `table()` can show you the n for all groups. 
```{r}
table(vg$genre)
```

Using `describeBy()` from the `psych` package can be a very quick and easy, but a bit annoying to look at. It also ignores missing data which is helpful.

* remember to install the `psych` package before using it. 


```{r, eval=FALSE}
library(psych)  ## this is not working on my computer

describeBy(vg, group = "genre")
```

Writing code using `tidyverse` can give us descriptive statistics in a more organized way. 

```{r}
vg %>% 
  group_by(genre) %>% 
  summarise(meanNA = mean(NA_sales))

```

If you had missing data, you'd do it like this. Also, `as.data.frame()` just helps us see decimal places. 


```{r}
vg %>% 
  group_by(genre) %>% 
  summarise(meanNA = mean(NA_sales, na.rm = T)) %>% 
  as.data.frame()
```

You can do several summaries at once like this

```{r}
vg %>% 
  group_by(genre) %>% 
  summarise(meanNA = mean(NA_sales),
            sd_NA = sd(NA_sales),
            meanEU = mean(EU_sales),
            sd_EU = sd(EU_sales)) %>% 
  as.data.frame()
```

To save time, you can tell it to just get the summary of all numeric columns. 

```{r}
vg$year <- as.factor(vg$year) # just need to make year non-numeric first


vg %>%
  group_by(genre) %>%
  summarise_if(is.numeric, mean, na.rm = T) %>%
  as.data.frame()


 vg %>%
  group_by(genre) %>%
  summarise_if(is.numeric, sd, na.rm = TRUE) %>%
  as.data.frame()

```

## Comparing population and sample means

Why we need the sample standard deviation. 

The sample SD is an estimate of the population SD. We need this estimate because we never have data from the full population but only random samples. 

The formula for population sd is the square root of the variance divided by N, where are the sample sd is the square root of the variance divided by n -1. 


```{r}
x <- c(14, 11, 5, 3, 8, 10, 9, 15)

pop.sd(x) 

sd(x) 
```
The is a .3 difference if the standard deviations. However, would the difference be as big with a bigger sample?

```{r}
set.seed(1) # just so we all get the same results

x <- rnorm(100, mean = 8) #100 random numbers with mean of 8.

pop.sd(x) 

sd(x)      
```

Sample SD is larger than population SD but this difference gets smaller as sample sizes increase.

For visual proof that using the population SD underestimates for samples. 

For the example say we have a population of 1000, with a mean of 199.91 and population SD of 8.28.

```{r}
set.seed(1)
population <- rnorm(1000, mean = 200, sd = 8)

mean(population)  #199.91
pop.sd(population)    #8.28
```

What if you did not know the real population SD and you were going to take samples of size 15 to try and estimate the population mean and SD. 

```{r}
s1 <- sample(population, 15, replace = T)

mean(s1) 

pop.sd(s1)  

sd(s1)   
```

Let's try another sample:

```{r}
s2 <- sample(population, 15, replace = T)

mean(s2) 

pop.sd(s2)  

sd(s2)   
```

So, in one sample the sample SD was closer to the real pop SD in the other, the popSD was closer to the real pop SD.

---- 

Now let's do this for 10,000 samples:

```{r}
results.means<- vector('list',10000)
results.popSD<- vector('list',10000)
results.sampSD<- vector('list',10000)

for(i in 1:10000){
  s <- sample(population, 15, replace = T)
  results.means[[i]] <- mean(s)
  results.popSD[[i]] <- pop.sd(s)
  results.sampSD[[i]] <- sd(s)
}
```

Sample mean, remember the population mean = 199.91

```{r}
means <- unlist(results.means) # sample means

mean(means) 
```

Standard deviations using the population SD
```{r}
popSDs <- unlist(results.popSD) # SDs using popSD

mean(popSDs)
```

Sample SDs
```{r}
sampSDs <- unlist(results.sampSD) # sample SDs

mean(sampSDs)
```

Now graph everything!


This shows the sample mean is a good etimate of the population mean, on average. 
```{r}
ggplot(data.frame(means), aes(x=means)) +
  geom_histogram(color='black', fill='blue', alpha=.2)+
  theme_classic() +
  geom_vline(xintercept = mean(means), lwd=1, color="black") +
  geom_vline(xintercept = 199.91, lwd=1, color="orange", lty=2) +
  ggtitle("Sample Means Distribution")
```

However, this shows the population SD formula with samples, leads us to underestimating the real population SD - on average there is a lot of variation though.

```{r}
ggplot(data.frame(sampSDs), aes(x=sampSDs)) +
  geom_histogram(color='black', fill='blue', alpha=.2)+
  theme_classic() +
  geom_vline(xintercept = mean(sampSDs), lwd=1, color="black") +
  geom_vline(xintercept = 8.28, lwd=1, color="orange", lty=2) +
  ggtitle("SD Distribution when using Sample SD")
```

Overall, using the sample SD formula with samples, provides a better estimate of the population SD on average. This is why we divided by n-1 for sample SD.