<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>11 Correlation | PSY317L Guides</title>
  <meta name="description" content="11 Correlation | PSY317L Guides" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="11 Correlation | PSY317L Guides" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="11 Correlation | PSY317L Guides" />
  
  
  

<meta name="author" content="James P. Curley &amp; Tyler M. Milewski" />


<meta name="date" content="2020-06-28" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="inferential-stats.html"/>
<link rel="next" href="regression.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Welcome to PSY317!</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#what-this-book-includes-and-what-it-doesnt"><i class="fa fa-check"></i><b>1.1</b> What this book includes and what it doesn't</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i><b>1.2</b> Acknowledgements</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#references"><i class="fa fa-check"></i><b>1.3</b> References</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#other-places-to-find-help-about-r"><i class="fa fa-check"></i><b>1.4</b> Other places to find help about R</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#other-places-to-find-help-about-r-and-statistics"><i class="fa fa-check"></i><b>1.5</b> Other places to find help about R and Statistics</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#introduction-1"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#downloading-r"><i class="fa fa-check"></i><b>2.2</b> Downloading R</a></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#downloading-rstudio"><i class="fa fa-check"></i><b>2.3</b> Downloading RStudio</a></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#using-rcloud-instead-of-rstudio"><i class="fa fa-check"></i><b>2.4</b> Using RCloud instead of RStudio</a></li>
<li class="chapter" data-level="2.5" data-path="introduction.html"><a href="introduction.html#importing-data"><i class="fa fa-check"></i><b>2.5</b> Importing Data</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="basic-syntax.html"><a href="basic-syntax.html"><i class="fa fa-check"></i><b>3</b> Basic Syntax</a><ul>
<li class="chapter" data-level="3.1" data-path="basic-syntax.html"><a href="basic-syntax.html#boring-mathematical-stuff"><i class="fa fa-check"></i><b>3.1</b> boring mathematical stuff</a></li>
<li class="chapter" data-level="3.2" data-path="basic-syntax.html"><a href="basic-syntax.html#assignment"><i class="fa fa-check"></i><b>3.2</b> assignment</a></li>
<li class="chapter" data-level="3.3" data-path="basic-syntax.html"><a href="basic-syntax.html#vectors"><i class="fa fa-check"></i><b>3.3</b> vectors</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html"><i class="fa fa-check"></i><b>4</b> Introduction to Data Carpentry</a><ul>
<li class="chapter" data-level="4.1" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#tidyverse"><i class="fa fa-check"></i><b>4.1</b> tidyverse</a></li>
<li class="chapter" data-level="4.2" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#filter"><i class="fa fa-check"></i><b>4.2</b> filter()</a></li>
<li class="chapter" data-level="4.3" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#select"><i class="fa fa-check"></i><b>4.3</b> select()</a></li>
<li class="chapter" data-level="4.4" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#arrange"><i class="fa fa-check"></i><b>4.4</b> arrange()</a></li>
<li class="chapter" data-level="4.5" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#mutate"><i class="fa fa-check"></i><b>4.5</b> mutate()</a></li>
<li class="chapter" data-level="4.6" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#wide-vs-long-data"><i class="fa fa-check"></i><b>4.6</b> Wide vs Long Data</a></li>
<li class="chapter" data-level="4.7" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#joins"><i class="fa fa-check"></i><b>4.7</b> Joins</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="data-visualization.html"><a href="data-visualization.html"><i class="fa fa-check"></i><b>5</b> Data Visualization</a><ul>
<li class="chapter" data-level="5.1" data-path="data-visualization.html"><a href="data-visualization.html#scatter-plots"><i class="fa fa-check"></i><b>5.1</b> Scatter Plots</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="r-ggplotdf-x-y-geom-point.html"><a href="r-ggplotdf-x-y-geom-point.html"><i class="fa fa-check"></i><b>6</b> <code>{r} # ggplot(df, (x = , y = )) + #   geom_point() #</code></a></li>
<li class="chapter" data-level="7" data-path="descriptives.html"><a href="descriptives.html"><i class="fa fa-check"></i><b>7</b> Descriptives</a></li>
<li class="chapter" data-level="8" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>8</b> Distributions</a></li>
<li class="chapter" data-level="9" data-path="confidence-intervals.html"><a href="confidence-intervals.html"><i class="fa fa-check"></i><b>9</b> Confidence Intervals</a></li>
<li class="chapter" data-level="10" data-path="inferential-stats.html"><a href="inferential-stats.html"><i class="fa fa-check"></i><b>10</b> Inferential Stats</a><ul>
<li class="chapter" data-level="10.1" data-path="inferential-stats.html"><a href="inferential-stats.html#comparing-two-samples"><i class="fa fa-check"></i><b>10.1</b> Comparing two Samples</a></li>
<li class="chapter" data-level="10.2" data-path="inferential-stats.html"><a href="inferential-stats.html#independent-samples-t-test"><i class="fa fa-check"></i><b>10.2</b> Independent Samples t-test</a></li>
<li class="chapter" data-level="10.3" data-path="inferential-stats.html"><a href="inferential-stats.html#background-to-students-2-sample-t-test"><i class="fa fa-check"></i><b>10.3</b> Background to Student's 2 Sample t-test</a></li>
<li class="chapter" data-level="10.4" data-path="inferential-stats.html"><a href="inferential-stats.html#sampling-distribution-of-the-difference-in-sample-means"><i class="fa fa-check"></i><b>10.4</b> Sampling Distribution of the Difference in Sample Means</a></li>
<li class="chapter" data-level="10.5" data-path="inferential-stats.html"><a href="inferential-stats.html#pooled-standard-deviation"><i class="fa fa-check"></i><b>10.5</b> Pooled Standard Deviation</a></li>
<li class="chapter" data-level="10.6" data-path="inferential-stats.html"><a href="inferential-stats.html#confidence-interval-for-difference-in-means"><i class="fa fa-check"></i><b>10.6</b> Confidence Interval for Difference in Means</a></li>
<li class="chapter" data-level="10.7" data-path="inferential-stats.html"><a href="inferential-stats.html#conducting-student-t-test"><i class="fa fa-check"></i><b>10.7</b> Conducting Student t-test</a></li>
<li class="chapter" data-level="10.8" data-path="inferential-stats.html"><a href="inferential-stats.html#doing-student-t-test-in-r"><i class="fa fa-check"></i><b>10.8</b> Doing Student t-test in R</a></li>
<li class="chapter" data-level="10.9" data-path="inferential-stats.html"><a href="inferential-stats.html#effect-sizes"><i class="fa fa-check"></i><b>10.9</b> Effect Sizes</a></li>
<li class="chapter" data-level="10.10" data-path="inferential-stats.html"><a href="inferential-stats.html#paired-t-tests"><i class="fa fa-check"></i><b>10.10</b> Paired t-tests</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="correlation.html"><a href="correlation.html"><i class="fa fa-check"></i><b>11</b> Correlation</a><ul>
<li class="chapter" data-level="11.1" data-path="correlation.html"><a href="correlation.html#pearson-correlation"><i class="fa fa-check"></i><b>11.1</b> Pearson Correlation</a></li>
<li class="chapter" data-level="11.2" data-path="correlation.html"><a href="correlation.html#calculating-the-pearson-correlation-in-r"><i class="fa fa-check"></i><b>11.2</b> Calculating the Pearson Correlation in R</a></li>
<li class="chapter" data-level="11.3" data-path="correlation.html"><a href="correlation.html#cross-products"><i class="fa fa-check"></i><b>11.3</b> Cross-products</a></li>
<li class="chapter" data-level="11.4" data-path="correlation.html"><a href="correlation.html#conducting-a-pearson-correlation-test"><i class="fa fa-check"></i><b>11.4</b> Conducting a Pearson Correlation Test</a></li>
<li class="chapter" data-level="11.5" data-path="correlation.html"><a href="correlation.html#assumptions-of-pearsons-correlation"><i class="fa fa-check"></i><b>11.5</b> Assumptions of Pearson's Correlation</a></li>
<li class="chapter" data-level="11.6" data-path="correlation.html"><a href="correlation.html#confidence-intervals-for-r"><i class="fa fa-check"></i><b>11.6</b> Confidence Intervals for R</a></li>
<li class="chapter" data-level="11.7" data-path="correlation.html"><a href="correlation.html#partial-correlations"><i class="fa fa-check"></i><b>11.7</b> Partial Correlations</a></li>
<li class="chapter" data-level="11.8" data-path="correlation.html"><a href="correlation.html#non-parametric-correlations"><i class="fa fa-check"></i><b>11.8</b> Non-parametric Correlations</a></li>
<li class="chapter" data-level="11.9" data-path="correlation.html"><a href="correlation.html#point-biserial-correlation"><i class="fa fa-check"></i><b>11.9</b> Point-Biserial Correlation</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>12</b> Regression</a></li>
<li class="chapter" data-level="13" data-path="permutation-testing.html"><a href="permutation-testing.html"><i class="fa fa-check"></i><b>13</b> Permutation Testing</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">PSY317L Guides</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="correlation" class="section level1">
<h1><span class="header-section-number">11</span> Correlation</h1>
<p>intro lines about what correlation is etc...</p>
<div id="pearson-correlation" class="section level2">
<h2><span class="header-section-number">11.1</span> Pearson Correlation</h2>
<p>Pearson's correlation is measured by <code>r</code> and ranges between -1 and +1. +1 indicates that the variables <code>X</code> and <code>Y</code> are maximally positively correlated, such that as values of X increase so do values of Y. -1 indicates a compleltely negative correlation such that as values of <code>X</code> increase, values of <code>Y</code> decrease. A value of 0 indicates that there is no overall relationship.</p>
<p><em>insert figure of negative 0.6, 0 and positive 0.6 here</em></p>
<p>The below image shows scatterplots, each with a sample size of 30. The trendline is to help demonstrate how correlations of different magnitudes look in terms of their association.</p>
<div class="figure">
<img src="img/correlations.png" alt="Correlations" />
<p class="caption">Correlations</p>
</div>
</div>
<div id="calculating-the-pearson-correlation-in-r" class="section level2">
<h2><span class="header-section-number">11.2</span> Calculating the Pearson Correlation in R</h2>
<p>To calculate the correlation coefficient in R, it's pretty straightforward. You simply can use the <code>cor()</code> function. For instance, let's correlate...</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(<span class="dv">1</span>:<span class="dv">10</span>,<span class="dv">1</span>:<span class="dv">10</span>) <span class="co"># replace with an example</span></code></pre></div>
<pre><code>## [1] 1</code></pre>
<p>Before we go further into what we should do with these correlations, and how to signficance test them, let's learn a little bit more about how they come about.</p>
</div>
<div id="cross-products" class="section level2">
<h2><span class="header-section-number">11.3</span> Cross-products</h2>
<p>The formula for calculating the Pearson's correlation coefficient for a sample is:</p>
<p><span class="math inline">\(r = \frac{\sum_{}^{} z_{x}z_{y}}{n - 1}\)</span></p>
<p>When we have a population, we can use the formula:</p>
<p><span class="math inline">\(r = \frac{\sum_{}^{} z_{x}z_{y}}{N}\)</span></p>
<p>Essentially, the steps are to convert all the <code>X</code> and <code>Y</code> scores into their respective z-scores. Then you mutliply these two values together to get the <code>cross-product</code>. After summing up all the cross-products for each data point, we divide this number by <code>n-1</code> if we're dealing with a sample (we usually are), or <code>N</code> if we're dealing with a population.</p>
<p>The sum of the cross-products will therefore be largely positive if positive z-scores are multiple together or if negative z-scores are multiplied together. The sum of the cross-products will be largely negative if negative z-scores are multipled with positive z-scores.</p>
<p>The following example should help make this clearer. Look at the following data, its scatterplot and the correlation coefficient. They show that we have a positive correlation of <code>r=0.84</code>. Let's break it down how we got that value.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">1.1</span>, <span class="fl">1.5</span>, <span class="fl">2.1</span>, <span class="fl">3.5</span>, <span class="fl">3.6</span>, <span class="fl">3.5</span>, <span class="fl">2.6</span>, <span class="fl">5.6</span>, <span class="fl">4.4</span>, <span class="fl">3.9</span>)
y &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">2.8</span>, <span class="fl">2.9</span>, <span class="fl">1.6</span>, <span class="fl">5.5</span>, <span class="fl">4.7</span>, <span class="fl">8.1</span>, <span class="fl">3.3</span>, <span class="fl">7.7</span>, <span class="fl">7.1</span>, <span class="fl">5.8</span>)

df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(x, y)

df</code></pre></div>
<pre><code>##      x   y
## 1  1.1 2.8
## 2  1.5 2.9
## 3  2.1 1.6
## 4  3.5 5.5
## 5  3.6 4.7
## 6  3.5 8.1
## 7  2.6 3.3
## 8  5.6 7.7
## 9  4.4 7.1
## 10 3.9 5.8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(df, <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y)) +<span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">size=</span><span class="dv">2</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-37-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(x,y)</code></pre></div>
<pre><code>## [1] 0.8418262</code></pre>
<p>First, let's calculate the means and standard deviation (using <code>sd</code> so a sample standard deviation) of <code>x</code> and <code>y</code>. We need to get these values so we can calculate the z-scores of each.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># step 1:  Get the mean and sd of x and y</span>


<span class="kw">mean</span>(x)</code></pre></div>
<pre><code>## [1] 3.18</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sd</span>(x)</code></pre></div>
<pre><code>## [1] 1.370158</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(y)</code></pre></div>
<pre><code>## [1] 4.95</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sd</span>(y)</code></pre></div>
<pre><code>## [1] 2.259916</code></pre>
<p>Now, we can calculate the z-scores, remembering that the formula for that is:</p>
<p><span class="math inline">\(z = \frac{x - \overline{x}}{s_{x}}\)</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># step 2. Calculate z-scores of x, and z-scores of y.</span>

df$zx &lt;-<span class="st"> </span>(x -<span class="st"> </span><span class="kw">mean</span>(x)) /<span class="st"> </span><span class="kw">sd</span>(x)  <span class="co"># z scores of x</span>
df$zy &lt;-<span class="st"> </span>(y -<span class="st"> </span><span class="kw">mean</span>(y)) /<span class="st"> </span><span class="kw">sd</span>(y)  <span class="co"># z scores of y</span>

df</code></pre></div>
<pre><code>##      x   y         zx         zy
## 1  1.1 2.8 -1.5180729 -0.9513626
## 2  1.5 2.9 -1.2261358 -0.9071132
## 3  2.1 1.6 -0.7882302 -1.4823557
## 4  3.5 5.5  0.2335497  0.2433718
## 5  3.6 4.7  0.3065340 -0.1106236
## 6  3.5 8.1  0.2335497  1.3938569
## 7  2.6 3.3 -0.4233088 -0.7301155
## 8  5.6 7.7  1.7662195  1.2168592
## 9  4.4 7.1  0.8904082  0.9513626
## 10 3.9 5.8  0.5254868  0.3761201</code></pre>
<p>Following this, we simply multiple the z-scores of <code>x</code> and <code>y</code> against each other for every data point:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># step 3. Calculate the cross-product:  zx * zy</span>

df$zxzy &lt;-<span class="st"> </span>df$zx *<span class="st"> </span>df$zy

df</code></pre></div>
<pre><code>##      x   y         zx         zy        zxzy
## 1  1.1 2.8 -1.5180729 -0.9513626  1.44423785
## 2  1.5 2.9 -1.2261358 -0.9071132  1.11224399
## 3  2.1 1.6 -0.7882302 -1.4823557  1.16843751
## 4  3.5 5.5  0.2335497  0.2433718  0.05683941
## 5  3.6 4.7  0.3065340 -0.1106236 -0.03390988
## 6  3.5 8.1  0.2335497  1.3938569  0.32553483
## 7  2.6 3.3 -0.4233088 -0.7301155  0.30906432
## 8  5.6 7.7  1.7662195  1.2168592  2.14924036
## 9  4.4 7.1  0.8904082  0.9513626  0.84710104
## 10 3.9 5.8  0.5254868  0.3761201  0.19764615</code></pre>
<p>We now have all of our cross-products. Notice why the majority are positive. This is because we have multiplied positive <span class="math inline">\(z_{x}\)</span> with positive <span class="math inline">\(z_{y}\)</span> or we multiplied negative <span class="math inline">\(z_{x}\)</span> with negative <span class="math inline">\(z_{y}\)</span>. This happens because datapoints that tend to be above the mean for <code>x</code> are also above the mean for <code>y</code>, and points that are below the mean of <code>x</code> are also below the mean of <code>y</code>.</p>
<p>We can add this up to get the sum of the cross-products. That is the <span class="math inline">\(\sum_{}^{} z_{x}z_{y}\)</span> in the formula.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># step 4.  Sum up the cross products.</span>

<span class="kw">sum</span>(df$zxzy) <span class="co"># 7.58</span></code></pre></div>
<pre><code>## [1] 7.576436</code></pre>
<p>We now divide that by <code>n-1</code> as we have a sample, to get the correlation coefficient <code>r</code>. That gives us an estimation of the average cross-product.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># step 5- calculate &#39;r&#39; by dividing by n-1. (for a sample)</span>

<span class="kw">sum</span>(df$zxzy) /<span class="st"> </span><span class="dv">9</span>   <span class="co"># our n was 10, so n-1 = 9</span></code></pre></div>
<pre><code>## [1] 0.8418262</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(df$zxzy) /<span class="st"> </span>(<span class="kw">nrow</span>(df) -<span class="st"> </span><span class="dv">1</span>)  <span class="co"># nrow(df) is more generalizable</span></code></pre></div>
<pre><code>## [1] 0.8418262</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># r=0.84</span></code></pre></div>
<p>Just as a quick second example, here is a work through calculating a negative correlation. Notice the <span class="math inline">\(z_{x}\)</span> and <span class="math inline">\(z_{y}\)</span> scores that are multiplied together. They are largely opposite in terms of signs. This is what leads to a negative sum of cross-products and the negative correlation. Why? Because data points that are above the mean for <code>x</code> are generally below the mean in terms of <code>y</code> and visa-versa.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">### Example 2.   Negative Correlation.

x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">1.1</span>, <span class="fl">1.5</span>, <span class="fl">2.1</span>, <span class="fl">3.5</span>, <span class="fl">3.6</span>, <span class="fl">3.5</span>, <span class="fl">2.6</span>, <span class="fl">5.6</span>, <span class="fl">4.4</span>, <span class="fl">3.9</span>)
y &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">10.4</span>, <span class="fl">10.0</span>, <span class="fl">8.4</span>, <span class="fl">8.5</span>, <span class="fl">8.4</span>, <span class="fl">6.3</span>, <span class="fl">7.1</span>, <span class="fl">6.2</span>, <span class="fl">8.1</span>, <span class="fl">10.0</span>)

df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(x, y)

<span class="kw">ggplot</span>(df, <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y)) +<span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">size=</span><span class="dv">2</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-43-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(df$x,df$y) </code></pre></div>
<pre><code>## [1] -0.6112965</code></pre>
<p>Here is the code, truncated for space:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Calculate z-scores for each x and each y</span>
df$zx &lt;-<span class="st"> </span>(x -<span class="st"> </span><span class="kw">mean</span>(x)) /<span class="st"> </span><span class="kw">sd</span>(x)
df$zy &lt;-<span class="st"> </span>(y -<span class="st"> </span><span class="kw">mean</span>(y)) /<span class="st"> </span><span class="kw">sd</span>(y)

<span class="co"># Calculate the cross-product:  zx * zy</span>
df$zxzy &lt;-<span class="st"> </span>df$zx *<span class="st"> </span>df$zy

<span class="co"># let&#39;s look at the dataframe</span>
<span class="co"># notice the cross products:</span>
df</code></pre></div>
<pre><code>##      x    y         zx          zy        zxzy
## 1  1.1 10.4 -1.5180729  1.37762597 -2.09133671
## 2  1.5 10.0 -1.2261358  1.11012578 -1.36116500
## 3  2.1  8.4 -0.7882302  0.04012503 -0.03162776
## 4  3.5  8.5  0.2335497  0.10700008  0.02498983
## 5  3.6  8.4  0.3065340  0.04012503  0.01229968
## 6  3.5  6.3  0.2335497 -1.36425096 -0.31862038
## 7  2.6  7.1 -0.4233088 -0.82925058  0.35102907
## 8  5.6  6.2  1.7662195 -1.43112601 -2.52768263
## 9  4.4  8.1  0.8904082 -0.16050011 -0.14291061
## 10 3.9 10.0  0.5254868  1.11012578  0.58335643</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Sum up the cross products and Calculate &#39;r&#39; by dividing by N-1.</span>

<span class="kw">sum</span>(df$zxzy) /<span class="st"> </span>(<span class="kw">nrow</span>(df) -<span class="st"> </span><span class="dv">1</span>)</code></pre></div>
<pre><code>## [1] -0.6112965</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(df$x,df$y) </code></pre></div>
<pre><code>## [1] -0.6112965</code></pre>
</div>
<div id="conducting-a-pearson-correlation-test" class="section level2">
<h2><span class="header-section-number">11.4</span> Conducting a Pearson Correlation Test</h2>
<p>Although <code>cor()</code> gives you the correlation between two continuous variables, to actually run a significance test, you need to use <code>cor.test()</code>.</p>
<p>Let's use some BlueJay data to do this. We'll just use data on male birds.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
jays &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data/BlueJays.csv&quot;</span>)</code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   BirdID = col_character(),
##   KnownSex = col_character(),
##   BillDepth = col_double(),
##   BillWidth = col_double(),
##   BillLength = col_double(),
##   Head = col_double(),
##   Mass = col_double(),
##   Skull = col_double(),
##   Sex = col_integer()
## )</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">jayM &lt;-<span class="st"> </span>jays %&gt;%<span class="st"> </span><span class="kw">filter</span>(KnownSex ==<span class="st"> &quot;M&quot;</span>) <span class="co"># we&#39;ll just look at Males</span>

<span class="kw">nrow</span>(jayM) <span class="co"># 63 observations</span></code></pre></div>
<pre><code>## [1] 63</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(jayM)</code></pre></div>
<pre><code>## # A tibble: 6 x 9
##   BirdID     KnownSex BillDepth BillWidth BillLength  Head  Mass Skull   Sex
##   &lt;chr&gt;      &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;
## 1 0000-00000 M             8.26      9.21       25.9  56.6  73.3  30.7     1
## 2 1142-05901 M             8.54      8.76       25.0  56.4  75.1  31.4     1
## 3 1142-05905 M             8.39      8.78       26.1  57.3  70.2  31.2     1
## 4 1142-05909 M             8.71      9.84       25.5  57.3  74.9  31.8     1
## 5 1142-05912 M             8.74      9.28       25.4  57.1  75.1  31.8     1
## 6 1142-05914 M             8.72      9.94       30    60.7  78.1  30.7     1</code></pre>
<p>Let's say you're interested in examining whether there is an association between Body Mass and Head Size. First we'll make a scatterplot between the <code>Mass</code> and <code>Head</code> columns. We'll also investigate the correlation using <code>cor()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(jayM, <span class="kw">aes</span>(<span class="dt">x=</span>Mass, <span class="dt">y=</span>Head)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">shape =</span> <span class="dv">21</span>, <span class="dt">colour =</span> <span class="st">&quot;navy&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;dodgerblue&quot;</span>) +
<span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method=</span><span class="st">&quot;lm&quot;</span>, <span class="dt">se=</span>F)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-46-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(jayM$Mass, jayM$Head)  <span class="co"># r = 0.58,  a strong positive correlation.</span></code></pre></div>
<pre><code>## [1] 0.5773562</code></pre>
<p>To run the significance test, we do the following:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor.test</span>(jayM$Head, jayM$Mass) </code></pre></div>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  jayM$Head and jayM$Mass
## t = 5.5228, df = 61, p-value = 7.282e-07
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.3846090 0.7218601
## sample estimates:
##       cor 
## 0.5773562</code></pre>
<p>This gives us a lot of information. Firstly, at the bottom it repeats the correlation coefficient <code>cor</code>. At the top, it gives us the value of <code>t</code> which is essentially how surprising it is for us to get the correlation we did assuming we were drawing our sample from a population where there is no correlation. Associated with this <code>t</code> value is the degrees of freedom which is equal to <code>n-2</code>, so in this case that is <code>63-2 = 61</code>. The p-value is also given. If we are using <code>alpha=0.05</code> as our significance level, then we can reject the hypothesis that there is no overall correlation in the population between Body Mass and Head size if <code>p&lt;0.05</code>.</p>
<p>The default for <code>cor.test()</code> is to do a two-tailed test. This is testing whether your observed correlation <code>r</code> is different from <code>r=0</code> in either the positive or negative direction. This default version also gives us the confidence interval for the correlation coefficient. Essentially, this gives us the interval in which we have a 95% confidence that the true population <code>r</code> lies (remember we just have data from one sample that theoretically comes from a population).</p>
<p>It's also possible however that you had an <strong>a priori</strong> prediction about the direction of the effect. For instance, you may have predicted that Body Mass would be positively correlated with Head Size. In this case, you could do a one-tailed correlation test, where your alternative hypothesis is that there is a positive correlation and the null is that the correlation coefficient is equal to 0 or less than 0.</p>
<p>To do one-tailed tests you need to add the <code>alternative</code> argument.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># testing if there is a positive correlation</span>
<span class="kw">cor.test</span>(jayM$Head, jayM$Mass, <span class="dt">alternative =</span> <span class="st">&quot;greater&quot;</span>) </code></pre></div>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  jayM$Head and jayM$Mass
## t = 5.5228, df = 61, p-value = 3.641e-07
## alternative hypothesis: true correlation is greater than 0
## 95 percent confidence interval:
##  0.4187194 1.0000000
## sample estimates:
##       cor 
## 0.5773562</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># testing if there is a negative correlation</span>
<span class="kw">cor.test</span>(jayM$Head, jayM$Mass, <span class="dt">alternative =</span> <span class="st">&quot;less&quot;</span>) </code></pre></div>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  jayM$Head and jayM$Mass
## t = 5.5228, df = 61, p-value = 1
## alternative hypothesis: true correlation is less than 0
## 95 percent confidence interval:
##  -1.0000000  0.7017994
## sample estimates:
##       cor 
## 0.5773562</code></pre>
</div>
<div id="assumptions-of-pearsons-correlation" class="section level2">
<h2><span class="header-section-number">11.5</span> Assumptions of Pearson's Correlation</h2>
<p>The Pearson Correlation Coefficient requires your data to be approximately normally distributed. To do this we have various options how to test for normality.</p>
<p>Firstly, we could do a Shapiro-Wilk test, which formally determines whether our data are normal. This is done using <code>shapiro.test()</code>, where we assume our data are from a normal population if the resulting p-value is above 0.05. If the p-value is below 0.05 then we have evidence to reject that our data come from a normal population.</p>
<p>With our data above, this would look like this when running the test on each variable:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">shapiro.test</span>(jayM$Mass)  <span class="co"># P &gt; 0.05, therefore cannot reject null that data is not normal</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  jayM$Mass
## W = 0.97222, p-value = 0.1647</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">shapiro.test</span>(jayM$Head)  <span class="co"># P &gt; 0.05, therefore cannot reject null that data is not normal</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  jayM$Head
## W = 0.96521, p-value = 0.07189</code></pre>
<p>We can also make a QQ-plot for each variable. Essentially what we require from this plot is for the majority of our data to fall on the straight line - especially the datapoints in the middle. Some deviation at the tails is ok. This plot orders our data and plots the observed data against values on the x-axis that we would expect to get if our data was truly from a normal population.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qqnorm</span>(jayM$Mass)
<span class="kw">qqline</span>(jayM$Mass, <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-51-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qqnorm</span>(jayM$Head)
<span class="kw">qqline</span>(jayM$Head, <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-52-1.png" width="672" /></p>
<p>Both of these QQ plots are ok, and indicate normality, as does our Shapiro-Wilk tests. Therefore we would be ok to use a Pearson Correlation test with these data.</p>
<p>What should you do though if either of your continuous variables are not approximately normally distributed? In that case, there are other correlation coefficients and associated significance tests that you could run instead. We describe these in more detail in Section x.xxx</p>
</div>
<div id="confidence-intervals-for-r" class="section level2">
<h2><span class="header-section-number">11.6</span> Confidence Intervals for R</h2>
<p>bit more on this and the theory.</p>
</div>
<div id="partial-correlations" class="section level2">
<h2><span class="header-section-number">11.7</span> Partial Correlations</h2>
<p>why.... the stupid formula.... and how to do in R.... and that there are technically better ways...</p>
</div>
<div id="non-parametric-correlations" class="section level2">
<h2><span class="header-section-number">11.8</span> Non-parametric Correlations</h2>
<p>examples....</p>
<p>when I can be bothered, edit this code chunk down into words + code</p>
<p>When at least on of our variables are not normal, then we need to consider alternative approaches to the Pearson correlation for assessing correlations.</p>
<p>Let's take this example, where we are interested in seeing if there's an association between saturated fat and cholesterol levels across a bunch of different cheeses:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)

cheese &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data/cheese.csv&quot;</span>)</code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   type = col_character(),
##   sat_fat = col_double(),
##   polysat_fat = col_double(),
##   monosat_fat = col_double(),
##   protein = col_double(),
##   carb = col_double(),
##   chol = col_integer(),
##   fiber = col_double(),
##   kcal = col_integer()
## )</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(cheese)</code></pre></div>
<pre><code>## # A tibble: 6 x 9
##   type      sat_fat polysat_fat monosat_fat protein  carb  chol fiber  kcal
##   &lt;chr&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt;
## 1 blue         18.7       0.8          7.78    21.4  2.34    75     0   353
## 2 brick        18.8       0.784        8.60    23.2  2.79    94     0   371
## 3 brie         17.4       0.826        8.01    20.8  0.45   100     0   334
## 4 camembert    15.3       0.724        7.02    19.8  0.46    72     0   300
## 5 caraway      18.6       0.83         8.28    25.2  3.06    93     0   376
## 6 cheddar      21.1       0.942        9.39    24.9  1.28   105     0   403</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># let&#39;s make a scatterplot of saturated fat against cholesterol</span>
<span class="kw">ggplot</span>(cheese, <span class="kw">aes</span>(<span class="dt">x =</span> sat_fat, <span class="dt">y =</span> chol)) +<span class="st"> </span><span class="kw">geom_point</span>() +
<span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method=</span><span class="st">&quot;lm&quot;</span>,<span class="dt">se=</span>F)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-53-1.png" width="672" /></p>
<p>It looks like there is a pretty obvious relationship, but let's check the normality of each variable before progressing. Firstly the Shapiro-Wilk tests suggest that our data do not come from a normal distribution:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">shapiro.test</span>(cheese$sat_fat)  <span class="co"># P &lt; 0.05, therefore data may not be normal</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  cheese$sat_fat
## W = 0.85494, p-value = 6.28e-07</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">shapiro.test</span>(cheese$chol)  <span class="co"># P &lt; 0.05,  therefore data may not be normal</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  cheese$chol
## W = 0.90099, p-value = 2.985e-05</code></pre>
<p>Secondly, we have quite dramatic deviation from the straight line of our datapoints in our QQ plots. This indicates that our dat are likley skewed.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qqnorm</span>(cheese$sat_fat)
<span class="kw">qqline</span>(cheese$sat_fat, <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-55-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qqnorm</span>(cheese$chol)
<span class="kw">qqline</span>(cheese$chol, <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-55-2.png" width="672" /></p>
<p>We could be thorough and check this by plotting histograms of our data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(gridExtra)</code></pre></div>
<pre><code>## 
## Attaching package: &#39;gridExtra&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     combine</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p1 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(cheese, <span class="kw">aes</span>(<span class="dt">x=</span>sat_fat)) +<span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&quot;black&quot;</span>, <span class="dt">fill=</span><span class="st">&quot;lightseagreen&quot;</span>)
p2 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(cheese, <span class="kw">aes</span>(<span class="dt">x=</span>chol)) +<span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&quot;black&quot;</span>, <span class="dt">fill=</span><span class="st">&quot;lightseagreen&quot;</span>)

<span class="kw">grid.arrange</span>(p1,p2,<span class="dt">nrow=</span><span class="dv">1</span>)</code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-56-1.png" width="672" /></p>
<p>Because our data do not appear to be normal, we cannot do a Pearson correlation coefficient. We should instead use a non-parametric correlation method. There are several of these to choose from. We don't plan to go into the details here of how these methods determine their correlation coefficients or conduct significance test. In brief, these methods generally rank order the datapoints along the <code>x</code> and <code>y</code> axes and then determine how ordered these ranks are with respect to each other.</p>
<p>Probably the most commonly used non-parametric correlation test is called the Spearman Rank Correlation test.</p>
<p>To run this, we can use <code>cor()</code> to get the correlation or <code>cor.test()</code> to run the signficance test in the same way we did the Pearson test. However, the difference here is that we specify <code>method=&quot;spearman&quot;</code> at the end.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(cheese$sat_fat, cheese$chol, <span class="dt">method =</span> <span class="st">&quot;spearman&quot;</span>)      </code></pre></div>
<pre><code>## [1] 0.8677042</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor.test</span>(cheese$sat_fat, cheese$chol, <span class="dt">method =</span> <span class="st">&quot;spearman&quot;</span>) </code></pre></div>
<pre><code>## Warning in cor.test.default(cheese$sat_fat, cheese$chol, method = &quot;spearman&quot;):
## Cannot compute exact p-value with ties</code></pre>
<pre><code>## 
##  Spearman&#39;s rank correlation rho
## 
## data:  cheese$sat_fat and cheese$chol
## S = 8575.9, p-value &lt; 2.2e-16
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##       rho 
## 0.8677042</code></pre>
<p>The correlation coefficient here is 0.87 and is termed <code>rho</code> instead of <code>r</code>. With the significance test, you get a test-statistic <code>S</code> which relates to how well ordered the ranked data are. Also provided is a p-value. As with the Pearson, the default is a 2-tailed test, testing whether the obsvered correlation could have come from a population with a correlation of 0. If the p-value is below 0.05 (using alpha = 0.05 as our criterion), then that is reasonable evidence that there is a significant correlation.</p>
<p>You may also notice with Spearman Rank correlations that you are forever getting warnings about computing p-values with ties. Don't worry at all about this - although this is an issue with the test and how it calculates the p-value, it isn't of any real practical concern.</p>
<p>If you were interested in conducting a one-tailed correlation test, you could do that in the same way as you did for the Pearson. For instance, if you predicted that cholesterol and saturated fat would have a positive correlation, you could do the following to do a one-tailed test:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor.test</span>(cheese$sat_fat, cheese$chol, <span class="dt">method =</span> <span class="st">&quot;spearman&quot;</span>, <span class="dt">alternative =</span> <span class="st">&quot;greater&quot;</span>) </code></pre></div>
<pre><code>## Warning in cor.test.default(cheese$sat_fat, cheese$chol, method = &quot;spearman&quot;, :
## Cannot compute exact p-value with ties</code></pre>
<pre><code>## 
##  Spearman&#39;s rank correlation rho
## 
## data:  cheese$sat_fat and cheese$chol
## S = 8575.9, p-value &lt; 2.2e-16
## alternative hypothesis: true rho is greater than 0
## sample estimates:
##       rho 
## 0.8677042</code></pre>
<p>You may also notice that the output of the Spearman Rank test does not give confidence intervals for the value of rho. This is unfortunate and is one of the drawbacks of doing a non-parametric correlation.</p>
<p>Finally, there are several other types of non-parametric correlations you could choose from if you didn't want to do a Spearman Rank correlation. We personally recommend using a method called <code>Kendalls Tau B</code> correlation, which can be done like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor.test</span>(cheese$sat_fat, cheese$chol, <span class="dt">method =</span> <span class="st">&quot;kendall&quot;</span>) </code></pre></div>
<pre><code>## 
##  Kendall&#39;s rank correlation tau
## 
## data:  cheese$sat_fat and cheese$chol
## z = 8.8085, p-value &lt; 2.2e-16
## alternative hypothesis: true tau is not equal to 0
## sample estimates:
##       tau 
## 0.7102531</code></pre>
<p>This output gives you a <code>tau</code> value which is the correlation coefficient, and a p-value which you can interpret in the same way as the other tests.</p>
<p><strong>Ranked Data</strong></p>
<p>If at least one of your variables of your data are rank (ordinal) data, then you should use non-parametric correlations.</p>
<p>In the following example, the data show the dominance rank, age, body size and testosterone levels for a group of 18 animals. Lower numbers of the ranks, indicate a higher ranking animal. An animal with rank 1 means that it is the most dominant individual.</p>
<p>Perhaps with such data you may be interested in seeing if there was an association between dominance rank and testosterone levels. Because your dominance rank measure is ordinal (a rank), then you should pick a non-parametric correlation.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">test &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data/testosterone.csv&quot;</span>)</code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   drank = col_integer(),
##   age = col_double(),
##   size = col_integer(),
##   testosterone = col_double()
## )</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(test)</code></pre></div>
<pre><code>## # A tibble: 6 x 4
##   drank   age  size testosterone
##   &lt;int&gt; &lt;dbl&gt; &lt;int&gt;        &lt;dbl&gt;
## 1     3  13     183          4.8
## 2     7   9     155          3.9
## 3     7   5.5   144          3.8
## 4     1  11.5   201          6.4
## 5    12   3.5   125          1.8
## 6     4  10     166          4.3</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(test, <span class="kw">aes</span>(<span class="dt">x =</span> drank, <span class="dt">y =</span> testosterone)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>() +
<span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se=</span>F) +
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Dominance Rank&quot;</span>) +
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Testosterone Level&quot;</span>) </code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-60-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(test$drank, test$testosterone, <span class="dt">method =</span> <span class="st">&quot;spearman&quot;</span>) <span class="co"># rho = -0.91</span></code></pre></div>
<pre><code>## [1] -0.9083378</code></pre>
<p>If you had the <em>a priori</em> prediction, that more dominant animals would have higher testosterone, then you could do a one-tailed test. This would mean that you expect there to be a negative correlation - as the rank number gets higher, the levels of testosterone would fall. In this case, you'd use <code>alternative = &quot;less&quot;</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor.test</span>(test$drank, test$testosterone, <span class="dt">method =</span> <span class="st">&quot;spearman&quot;</span>, <span class="dt">alternative =</span> <span class="st">&quot;less&quot;</span>) <span class="co"># 1- tailed</span></code></pre></div>
<pre><code>## Warning in cor.test.default(test$drank, test$testosterone, method =
## &quot;spearman&quot;, : Cannot compute exact p-value with ties</code></pre>
<pre><code>## 
##  Spearman&#39;s rank correlation rho
## 
## data:  test$drank and test$testosterone
## S = 1849.2, p-value = 9.367e-08
## alternative hypothesis: true rho is less than 0
## sample estimates:
##        rho 
## -0.9083378</code></pre>
</div>
<div id="point-biserial-correlation" class="section level2">
<h2><span class="header-section-number">11.9</span> Point-Biserial Correlation</h2>
<p>why, what....</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="inferential-stats.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
