<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>13 Permutation Testing | PSY317L Guides</title>
  <meta name="description" content="13 Permutation Testing | PSY317L Guides" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="13 Permutation Testing | PSY317L Guides" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="13 Permutation Testing | PSY317L Guides" />
  
  
  

<meta name="author" content="James P. Curley &amp; Tyler M. Milewski" />


<meta name="date" content="2020-06-28" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="regression.html"/>

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Welcome to PSY317!</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#what-this-book-includes-and-what-it-doesnt"><i class="fa fa-check"></i><b>1.1</b> What this book includes and what it doesn't</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i><b>1.2</b> Acknowledgements</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#references"><i class="fa fa-check"></i><b>1.3</b> References</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#other-places-to-find-help-about-r"><i class="fa fa-check"></i><b>1.4</b> Other places to find help about R</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#other-places-to-find-help-about-r-and-statistics"><i class="fa fa-check"></i><b>1.5</b> Other places to find help about R and Statistics</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#introduction-1"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#downloading-r"><i class="fa fa-check"></i><b>2.2</b> Downloading R</a></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#downloading-rstudio"><i class="fa fa-check"></i><b>2.3</b> Downloading RStudio</a></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#using-rcloud-instead-of-rstudio"><i class="fa fa-check"></i><b>2.4</b> Using RCloud instead of RStudio</a></li>
<li class="chapter" data-level="2.5" data-path="introduction.html"><a href="introduction.html#importing-data"><i class="fa fa-check"></i><b>2.5</b> Importing Data</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="basic-syntax.html"><a href="basic-syntax.html"><i class="fa fa-check"></i><b>3</b> Basic Syntax</a><ul>
<li class="chapter" data-level="3.1" data-path="basic-syntax.html"><a href="basic-syntax.html#boring-mathematical-stuff"><i class="fa fa-check"></i><b>3.1</b> boring mathematical stuff</a></li>
<li class="chapter" data-level="3.2" data-path="basic-syntax.html"><a href="basic-syntax.html#assignment"><i class="fa fa-check"></i><b>3.2</b> assignment</a></li>
<li class="chapter" data-level="3.3" data-path="basic-syntax.html"><a href="basic-syntax.html#vectors"><i class="fa fa-check"></i><b>3.3</b> vectors</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html"><i class="fa fa-check"></i><b>4</b> Introduction to Data Carpentry</a><ul>
<li class="chapter" data-level="4.1" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#tidyverse"><i class="fa fa-check"></i><b>4.1</b> tidyverse</a></li>
<li class="chapter" data-level="4.2" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#filter"><i class="fa fa-check"></i><b>4.2</b> filter()</a></li>
<li class="chapter" data-level="4.3" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#select"><i class="fa fa-check"></i><b>4.3</b> select()</a></li>
<li class="chapter" data-level="4.4" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#arrange"><i class="fa fa-check"></i><b>4.4</b> arrange()</a></li>
<li class="chapter" data-level="4.5" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#mutate"><i class="fa fa-check"></i><b>4.5</b> mutate()</a></li>
<li class="chapter" data-level="4.6" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#wide-vs-long-data"><i class="fa fa-check"></i><b>4.6</b> Wide vs Long Data</a></li>
<li class="chapter" data-level="4.7" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#joins"><i class="fa fa-check"></i><b>4.7</b> Joins</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="data-visualization.html"><a href="data-visualization.html"><i class="fa fa-check"></i><b>5</b> Data Visualization</a><ul>
<li class="chapter" data-level="5.1" data-path="data-visualization.html"><a href="data-visualization.html#scatter-plots"><i class="fa fa-check"></i><b>5.1</b> Scatter Plots</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="r-ggplotdf-x-y-geom-point.html"><a href="r-ggplotdf-x-y-geom-point.html"><i class="fa fa-check"></i><b>6</b> <code>{r} # ggplot(df, (x = , y = )) + #   geom_point() #</code></a></li>
<li class="chapter" data-level="7" data-path="descriptives.html"><a href="descriptives.html"><i class="fa fa-check"></i><b>7</b> Descriptives</a></li>
<li class="chapter" data-level="8" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>8</b> Distributions</a></li>
<li class="chapter" data-level="9" data-path="confidence-intervals.html"><a href="confidence-intervals.html"><i class="fa fa-check"></i><b>9</b> Confidence Intervals</a></li>
<li class="chapter" data-level="10" data-path="inferential-stats.html"><a href="inferential-stats.html"><i class="fa fa-check"></i><b>10</b> Inferential Stats</a><ul>
<li class="chapter" data-level="10.1" data-path="inferential-stats.html"><a href="inferential-stats.html#comparing-two-samples"><i class="fa fa-check"></i><b>10.1</b> Comparing two Samples</a></li>
<li class="chapter" data-level="10.2" data-path="inferential-stats.html"><a href="inferential-stats.html#independent-samples-t-test"><i class="fa fa-check"></i><b>10.2</b> Independent Samples t-test</a></li>
<li class="chapter" data-level="10.3" data-path="inferential-stats.html"><a href="inferential-stats.html#background-to-students-2-sample-t-test"><i class="fa fa-check"></i><b>10.3</b> Background to Student's 2 Sample t-test</a></li>
<li class="chapter" data-level="10.4" data-path="inferential-stats.html"><a href="inferential-stats.html#sampling-distribution-of-the-difference-in-sample-means"><i class="fa fa-check"></i><b>10.4</b> Sampling Distribution of the Difference in Sample Means</a></li>
<li class="chapter" data-level="10.5" data-path="inferential-stats.html"><a href="inferential-stats.html#pooled-standard-deviation"><i class="fa fa-check"></i><b>10.5</b> Pooled Standard Deviation</a></li>
<li class="chapter" data-level="10.6" data-path="inferential-stats.html"><a href="inferential-stats.html#confidence-interval-for-difference-in-means"><i class="fa fa-check"></i><b>10.6</b> Confidence Interval for Difference in Means</a></li>
<li class="chapter" data-level="10.7" data-path="inferential-stats.html"><a href="inferential-stats.html#conducting-student-t-test"><i class="fa fa-check"></i><b>10.7</b> Conducting Student t-test</a></li>
<li class="chapter" data-level="10.8" data-path="inferential-stats.html"><a href="inferential-stats.html#doing-student-t-test-in-r"><i class="fa fa-check"></i><b>10.8</b> Doing Student t-test in R</a></li>
<li class="chapter" data-level="10.9" data-path="inferential-stats.html"><a href="inferential-stats.html#effect-sizes"><i class="fa fa-check"></i><b>10.9</b> Effect Sizes</a></li>
<li class="chapter" data-level="10.10" data-path="inferential-stats.html"><a href="inferential-stats.html#paired-t-tests"><i class="fa fa-check"></i><b>10.10</b> Paired t-tests</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="correlation.html"><a href="correlation.html"><i class="fa fa-check"></i><b>11</b> Correlation</a><ul>
<li class="chapter" data-level="11.1" data-path="correlation.html"><a href="correlation.html#pearson-correlation"><i class="fa fa-check"></i><b>11.1</b> Pearson Correlation</a></li>
<li class="chapter" data-level="11.2" data-path="correlation.html"><a href="correlation.html#calculating-the-pearson-correlation-in-r"><i class="fa fa-check"></i><b>11.2</b> Calculating the Pearson Correlation in R</a></li>
<li class="chapter" data-level="11.3" data-path="correlation.html"><a href="correlation.html#cross-products"><i class="fa fa-check"></i><b>11.3</b> Cross-products</a></li>
<li class="chapter" data-level="11.4" data-path="correlation.html"><a href="correlation.html#conducting-a-pearson-correlation-test"><i class="fa fa-check"></i><b>11.4</b> Conducting a Pearson Correlation Test</a></li>
<li class="chapter" data-level="11.5" data-path="correlation.html"><a href="correlation.html#assumptions-of-pearsons-correlation"><i class="fa fa-check"></i><b>11.5</b> Assumptions of Pearson's Correlation</a></li>
<li class="chapter" data-level="11.6" data-path="correlation.html"><a href="correlation.html#confidence-intervals-for-r"><i class="fa fa-check"></i><b>11.6</b> Confidence Intervals for R</a></li>
<li class="chapter" data-level="11.7" data-path="correlation.html"><a href="correlation.html#partial-correlations"><i class="fa fa-check"></i><b>11.7</b> Partial Correlations</a></li>
<li class="chapter" data-level="11.8" data-path="correlation.html"><a href="correlation.html#non-parametric-correlations"><i class="fa fa-check"></i><b>11.8</b> Non-parametric Correlations</a></li>
<li class="chapter" data-level="11.9" data-path="correlation.html"><a href="correlation.html#point-biserial-correlation"><i class="fa fa-check"></i><b>11.9</b> Point-Biserial Correlation</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>12</b> Regression</a></li>
<li class="chapter" data-level="13" data-path="permutation-testing.html"><a href="permutation-testing.html"><i class="fa fa-check"></i><b>13</b> Permutation Testing</a><ul>
<li class="chapter" data-level="13.1" data-path="permutation-testing.html"><a href="permutation-testing.html#t-test-permutation"><i class="fa fa-check"></i><b>13.1</b> t-test Permutation</a><ul>
<li class="chapter" data-level="13.1.1" data-path="permutation-testing.html"><a href="permutation-testing.html#example-2"><i class="fa fa-check"></i><b>13.1.1</b> Example 2:</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="permutation-testing.html"><a href="permutation-testing.html#correlation-coefficient-permutation-tests"><i class="fa fa-check"></i><b>13.2</b> Correlation Coefficient Permutation Tests</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">PSY317L Guides</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="permutation-testing" class="section level1">
<h1><span class="header-section-number">13</span> Permutation Testing</h1>
<p>An example of permutation testing and the theory behind it.</p>
<div id="t-test-permutation" class="section level2">
<h2><span class="header-section-number">13.1</span> t-test Permutation</h2>
<p>Let's look at our two independent samples of exam scores:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)

anastasia &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">65</span>, <span class="dv">74</span>, <span class="dv">73</span>, <span class="dv">83</span>, <span class="dv">76</span>, <span class="dv">65</span>, <span class="dv">86</span>, <span class="dv">70</span>, <span class="dv">80</span>, <span class="dv">55</span>, <span class="dv">78</span>, <span class="dv">78</span>, <span class="dv">90</span>, <span class="dv">77</span>, <span class="dv">68</span>)
bernadette &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">72</span>, <span class="dv">66</span>, <span class="dv">71</span>, <span class="dv">66</span>, <span class="dv">76</span>, <span class="dv">69</span>, <span class="dv">79</span>, <span class="dv">73</span>, <span class="dv">62</span>, <span class="dv">69</span>, <span class="dv">68</span>, <span class="dv">60</span>, <span class="dv">73</span>, <span class="dv">68</span>, <span class="dv">67</span>, <span class="dv">74</span>, <span class="dv">56</span>, <span class="dv">74</span>)

<span class="co"># put into a dataframe:</span>
dd &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">values =</span> <span class="kw">c</span>(anastasia, bernadette),
                 <span class="dt">group =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&quot;Anastasia&quot;</span>,<span class="dv">15</span>), <span class="kw">rep</span>(<span class="st">&quot;Bernadette&quot;</span>, <span class="dv">18</span>))
)

dd</code></pre></div>
<pre><code>##    values      group
## 1      65  Anastasia
## 2      74  Anastasia
## 3      73  Anastasia
## 4      83  Anastasia
## 5      76  Anastasia
## 6      65  Anastasia
## 7      86  Anastasia
## 8      70  Anastasia
## 9      80  Anastasia
## 10     55  Anastasia
## 11     78  Anastasia
## 12     78  Anastasia
## 13     90  Anastasia
## 14     77  Anastasia
## 15     68  Anastasia
## 16     72 Bernadette
## 17     66 Bernadette
## 18     71 Bernadette
## 19     66 Bernadette
## 20     76 Bernadette
## 21     69 Bernadette
## 22     79 Bernadette
## 23     73 Bernadette
## 24     62 Bernadette
## 25     69 Bernadette
## 26     68 Bernadette
## 27     60 Bernadette
## 28     73 Bernadette
## 29     68 Bernadette
## 30     67 Bernadette
## 31     74 Bernadette
## 32     56 Bernadette
## 33     74 Bernadette</code></pre>
<p>We can plot these data as boxplots to get a sense of the within group variation as well as the observed differences between the groups:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(dd, <span class="kw">aes</span>(<span class="dt">x =</span> group, <span class="dt">y =</span> values, <span class="dt">fill =</span> group)) +
<span class="st">  </span><span class="kw">geom_boxplot</span>(<span class="dt">alpha=</span>.<span class="dv">3</span>, <span class="dt">outlier.shape =</span> <span class="ot">NA</span>) +
<span class="st">  </span><span class="kw">geom_jitter</span>(<span class="dt">width=</span>.<span class="dv">1</span>, <span class="dt">size=</span><span class="dv">2</span>) +
<span class="st">  </span><span class="kw">theme_classic</span>() +
<span class="st">  </span><span class="kw">scale_fill_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="st">&quot;firebrick&quot;</span>, <span class="st">&quot;dodgerblue&quot;</span>))</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-63-1.png" width="672" /></p>
<p>Now, from our two independent samples, we can directly observe what the difference in sample means is. This is just calculated by subtracting one sample mean from the other:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">meandif &lt;-<span class="st"> </span><span class="kw">mean</span>(anastasia)  -<span class="st"> </span><span class="kw">mean</span>(bernadette)   <span class="co"># 5.48</span>
meandif</code></pre></div>
<pre><code>## [1] 5.477778</code></pre>
<p>So, from our samples, we observed a difference in grades of 5.48 between the groups. Typically, we would run an independent t-test to test whether these two samples came from theoretical populations that differ in their means:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(anastasia, bernadette, <span class="dt">var.equal =</span> T)</code></pre></div>
<pre><code>## 
##  Two Sample t-test
## 
## data:  anastasia and bernadette
## t = 2.1154, df = 31, p-value = 0.04253
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##   0.1965873 10.7589683
## sample estimates:
## mean of x mean of y 
##  74.53333  69.05556</code></pre>
<p>This Student's t-test (notice <code>var.equal=T</code>) suggests that this is a significant difference, meaning that the groups do differ in their population means.</p>
<p>However, this test relies on several assumptions (see section xx.x.x). Instead, we could apply a permutation test that is free of assumptions.</p>
<p>Essentially what we are going to do is ask how surprising it was to get a difference of 5.48 given our real data. Put another way, if we shuffled the data into different groups of 15 and 18 (the respective sample sizes of Anastasia and Bernadette), would we get a difference in sample means of greater or lower than 5.48? If we did this thousands of times, how many times would we get differences in sample means above 5.48?</p>
<p>Let's apply this theory to just one permutation.</p>
<p>First, we combine all the data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1</span>) <span class="co"># just to keep the random number generator the same for all of us</span>

allscores &lt;-<span class="st"> </span><span class="kw">c</span>(anastasia, bernadette)

allscores</code></pre></div>
<pre><code>##  [1] 65 74 73 83 76 65 86 70 80 55 78 78 90 77 68 72 66 71 66 76 69 79 73 62 69
## [26] 68 60 73 68 67 74 56 74</code></pre>
<p>Next, we shuffle them into new groups of 15 and 18.:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">split</span>(<span class="kw">sample</span>(allscores), <span class="kw">rep</span>(<span class="dv">1</span>:<span class="dv">2</span>, <span class="kw">c</span>(<span class="dv">15</span>,<span class="dv">18</span>))) 

x</code></pre></div>
<pre><code>## $`1`
##  [1] 80 78 71 73 65 68 67 74 72 74 76 83 68 70 69
## 
## $`2`
##  [1] 74 90 69 68 78 66 73 76 62 56 79 65 60 73 55 77 66 86</code></pre>
<p>We have two brand new samples that contain all of the scores from our original data, but they've just been shuffled around. We could look at what the difference in sample means is between these two new samples:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x[[<span class="dv">1</span>]] <span class="co"># this is our shuffled sample of size 15</span></code></pre></div>
<pre><code>##  [1] 80 78 71 73 65 68 67 74 72 74 76 83 68 70 69</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x[[<span class="dv">2</span>]] <span class="co"># this is our shuffled sample of size 18</span></code></pre></div>
<pre><code>##  [1] 74 90 69 68 78 66 73 76 62 56 79 65 60 73 55 77 66 86</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(x[[<span class="dv">1</span>]])  <span class="co"># mean of the new sample of size 15</span></code></pre></div>
<pre><code>## [1] 72.53333</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(x[[<span class="dv">2</span>]])  <span class="co"># mean of the new sample of size 18</span></code></pre></div>
<pre><code>## [1] 70.72222</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># what&#39;s the difference in their means?</span>
<span class="kw">mean</span>(x[[<span class="dv">1</span>]]) -<span class="st"> </span><span class="kw">mean</span>(x[[<span class="dv">2</span>]]) </code></pre></div>
<pre><code>## [1] 1.811111</code></pre>
<p>The difference in sample means is 1.81, which is a lot smaller than our original difference in sample means.</p>
<p>Let's do this same process 10,000 times! Don't worry too much about the details of the code. What we are doing is the above process, just putting it in a loop and asking it to do it 10,000 times. We save all the results in an object called <code>results</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">results&lt;-<span class="kw">vector</span>(<span class="st">&#39;list&#39;</span>,<span class="dv">10000</span>)
for(i in <span class="dv">1</span>:<span class="dv">10000</span>){
  x &lt;-<span class="st"> </span><span class="kw">split</span>(<span class="kw">sample</span>(allscores), <span class="kw">rep</span>(<span class="dv">1</span>:<span class="dv">2</span>, <span class="kw">c</span>(<span class="dv">15</span>,<span class="dv">18</span>)))
  results[[i]]&lt;-<span class="kw">mean</span>(x[[<span class="dv">1</span>]]) -<span class="st"> </span><span class="kw">mean</span>(x[[<span class="dv">2</span>]])  
}

<span class="kw">head</span>(<span class="kw">unlist</span>(results)) <span class="co"># these are all our mean differences from 10,000 shuffles of the data. We&#39;re just looking at the first 6.</span></code></pre></div>
<pre><code>## [1] -1.8555556 -2.5888889  4.0111111 -3.9333333  0.2222222  3.5222222</code></pre>
<p>We can actually make a histogram showing the distribution of these differences in sample means.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">difs =</span> <span class="kw">unlist</span>(results))

<span class="kw">ggplot</span>(df, <span class="kw">aes</span>(<span class="dt">x=</span>difs)) +
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&quot;black&quot;</span>, <span class="dt">fill=</span><span class="st">&quot;green&quot;</span>, <span class="dt">alpha=</span>.<span class="dv">4</span>) +
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">color=</span><span class="st">&quot;navy&quot;</span>,<span class="dt">lwd=</span><span class="dv">1</span>,<span class="dt">lty=</span><span class="dv">2</span>,<span class="dt">xintercept =</span> <span class="fl">5.48</span>) +
<span class="st">  </span><span class="kw">theme_classic</span>()+
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Mean Differences from </span><span class="ch">\n</span><span class="st"> 10000 Permutations of Raw Data&quot;</span>)</code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-70-1.png" width="672" /></p>
<p>This histogram shows that for some of our 10,000 shuffles, we actually got some differences between our two samples of higher than 5.48 (the dotted blue line), but the vast majority of shuffles led to samples that had mean differences lower than 5.48. In fact, several shuffles led to samples where the sample of size 18 (Bernadette in the original data) had a sample mean that was higher than the sample of size 15 (Anastasia in the original data).</p>
<p>We can directly calculate how many times out of 10,000 shuffles we got a difference in sample means that was greater than 5.48</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(<span class="kw">unlist</span>(results) &gt;<span class="st"> </span><span class="fl">5.48</span>)  <span class="co"># 202 times out of 10000</span></code></pre></div>
<pre><code>## [1] 215</code></pre>
<p>To convert this to a p-value, we simply divide this value by the number of shuffles we ran - which was 10,000.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(<span class="kw">unlist</span>(results) &gt;<span class="st"> </span><span class="fl">5.48</span>) /<span class="dv">10000</span>  <span class="co"># which is 0.0202 proportion of the time</span></code></pre></div>
<pre><code>## [1] 0.0215</code></pre>
<p>So our p-value is <code>p=0.0215</code> which is similar to a one-tailed p-value.</p>
<div id="example-2" class="section level3">
<h3><span class="header-section-number">13.1.1</span> Example 2:</h3>
<p>Let's take a look at a second example. Here, we have various subjects rating their anxiety levels. They do this after either taking a new anxiolytic drug or a placebo. The subjects in each group are independent of each other. The placebo group has 19 subjects and the drug group has 21 subjects.</p>
<p>The data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">placebo &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">15</span>, <span class="dv">16</span>, <span class="dv">19</span>, <span class="dv">19</span>, <span class="dv">17</span>, <span class="dv">20</span>, <span class="dv">18</span>, <span class="dv">14</span>, <span class="dv">18</span>, <span class="dv">20</span>, <span class="dv">20</span>, <span class="dv">20</span>, <span class="dv">13</span>, <span class="dv">11</span>, <span class="dv">16</span>, <span class="dv">19</span>, <span class="dv">19</span>, <span class="dv">16</span>, <span class="dv">10</span>) 
drug &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">15</span>, <span class="dv">15</span>, <span class="dv">16</span>, <span class="dv">13</span>, <span class="dv">11</span>, <span class="dv">19</span>, <span class="dv">17</span>, <span class="dv">17</span>, <span class="dv">11</span>, <span class="dv">14</span>, <span class="dv">10</span>, <span class="dv">18</span>, <span class="dv">19</span>, <span class="dv">14</span>, <span class="dv">13</span>, <span class="dv">16</span>, <span class="dv">16</span>, <span class="dv">17</span>, <span class="dv">14</span>, <span class="dv">10</span>, <span class="dv">14</span>)


<span class="kw">length</span>(placebo) <span class="co">#19</span></code></pre></div>
<pre><code>## [1] 19</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">length</span>(drug)  <span class="co">#21</span></code></pre></div>
<pre><code>## [1] 21</code></pre>
<p>If we were interested in doing a Student's t-test, we might want to check whether the data are approximately normal. We could perform Shapiro-Wilk tests to do this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">shapiro.test</span>(drug)    <span class="co"># approximately normal as p&gt;.05</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  drug
## W = 0.95184, p-value = 0.3688</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">shapiro.test</span>(placebo) <span class="co"># not enough evidence to be normal as p&lt;.05</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  placebo
## W = 0.88372, p-value = 0.02494</code></pre>
<p>From this we find that the placebo group is not approximately normally distributed (p value of the Shapiro-Wilk test is &lt;.05). We could do a non-parametric test such as Wilcoxon Ranked Sum test (see xxx.xxx), but an alternative strategy is to perform a permutation test.</p>
<p>Let's first plot the data, and then look at our observed difference in anxiety scores between our two independent samples:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># put into dataframe - long format</span>
df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">anxiety =</span> <span class="kw">c</span>(placebo, drug),
                 <span class="dt">group =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&quot;placebo&quot;</span>, <span class="kw">length</span>(placebo)), 
                           <span class="kw">rep</span>(<span class="st">&quot;drug&quot;</span>, <span class="kw">length</span>(drug))
                 )
)

<span class="kw">head</span>(df)</code></pre></div>
<pre><code>##   anxiety   group
## 1      15 placebo
## 2      16 placebo
## 3      19 placebo
## 4      19 placebo
## 5      17 placebo
## 6      20 placebo</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#boxplots</span>
<span class="kw">ggplot</span>(df, <span class="kw">aes</span>(<span class="dt">x=</span>group, <span class="dt">y=</span>anxiety, <span class="dt">fill=</span>group)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_boxplot</span>(<span class="dt">outlier.shape =</span> <span class="ot">NA</span>, <span class="dt">alpha=</span>.<span class="dv">4</span>) +
<span class="st">  </span><span class="kw">geom_jitter</span>(<span class="dt">width=</span>.<span class="dv">1</span>) +
<span class="st">  </span><span class="kw">theme_classic</span>() +
<span class="st">  </span><span class="kw">scale_fill_manual</span>(<span class="dt">values=</span><span class="kw">c</span>(<span class="st">&quot;orange&quot;</span>, <span class="st">&quot;brown&quot;</span>))</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-75-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(placebo) -<span class="st"> </span><span class="kw">mean</span>(drug) <span class="co">#2.128</span></code></pre></div>
<pre><code>## [1] 2.12782</code></pre>
<p>So our observed difference in sample means is 2.128. In the permutation test, what we'll do is shuffle all the scores randomly between the two groups, creating new samples of the same size (19 and 21). Then we'll see what difference in sample means we get from those shuffled groups. We'll also do this 10,000 times.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">allvalues &lt;-<span class="st"> </span><span class="kw">c</span>(placebo, drug)

results&lt;-<span class="kw">vector</span>(<span class="st">&#39;list&#39;</span>,<span class="dv">10000</span>)
for(i in <span class="dv">1</span>:<span class="dv">10000</span>){
  x &lt;-<span class="st"> </span><span class="kw">split</span>(<span class="kw">sample</span>(allvalues), <span class="kw">rep</span>(<span class="dv">1</span>:<span class="dv">2</span>, <span class="kw">c</span>(<span class="dv">19</span>,<span class="dv">21</span>)))
  results[[i]]&lt;-<span class="kw">mean</span>(x[[<span class="dv">1</span>]]) -<span class="st"> </span><span class="kw">mean</span>(x[[<span class="dv">2</span>]])  
}

<span class="kw">head</span>(<span class="kw">unlist</span>(results)) <span class="co"># these are the first six of all our mean differences from 10,000 shuffles of the data.</span></code></pre></div>
<pre><code>## [1] -0.8796992 -0.7794486 -1.2807018 -0.4786967  2.5288221  1.1253133</code></pre>
<p>Let's plot the distribution of these data to see what proportion of times our shuffled groups got samples that were greater than 2.128.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df0 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">difs =</span> <span class="kw">unlist</span>(results))

<span class="kw">ggplot</span>(df0, <span class="kw">aes</span>(<span class="dt">x=</span>difs)) +
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&quot;black&quot;</span>, <span class="dt">fill=</span><span class="st">&quot;pink&quot;</span>, <span class="dt">alpha=</span>.<span class="dv">4</span>) +
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">color=</span><span class="st">&quot;navy&quot;</span>,<span class="dt">lwd=</span><span class="dv">1</span>,<span class="dt">lty=</span><span class="dv">2</span>,<span class="dt">xintercept =</span> <span class="fl">2.128</span>) +
<span class="st">  </span><span class="kw">theme_classic</span>()+
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Mean Differences from </span><span class="ch">\n</span><span class="st"> 10000 Permutations of Raw Data&quot;</span>)</code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-77-1.png" width="672" /></p>
<p>It looks like very few times did we get two samples that had differences in sample means that were greater than 2.128. We can calculate exactly how many times, and express this as the proportion of times we got a difference in sample means greater than 2.128:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(<span class="kw">unlist</span>(results) &gt;<span class="st"> </span><span class="fl">2.128</span>)  <span class="co"># 109 times out of 10000</span></code></pre></div>
<pre><code>## [1] 113</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(<span class="kw">unlist</span>(results) &gt;<span class="st"> </span><span class="fl">2.128</span>) /<span class="dv">10000</span>  <span class="co"># which is 0.0109 proportion of the time</span></code></pre></div>
<pre><code>## [1] 0.0113</code></pre>
<p>So, in this case we can say that the probability of getting a difference in sample means between the drug and placebo groups that was larger than our observed difference of 2.128 was <code>p = 0.0109</code>. This is very strong evidence that the observed difference is significantly greater than we'd expect by chance.</p>
</div>
</div>
<div id="correlation-coefficient-permutation-tests" class="section level2">
<h2><span class="header-section-number">13.2</span> Correlation Coefficient Permutation Tests</h2>
<p>You can apply the logic of permutation tests to almost any statistical test. Let's look at an example for Pearson correlations.</p>
<p>In these data, we are looking at 15 subjects who are completing a task. We measured the time they spent on the task and their high scores.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)

df &lt;-<span class="st">  </span><span class="kw">read_csv</span>(<span class="st">&quot;data/timescore.csv&quot;</span>)</code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   subject = col_character(),
##   time = col_double(),
##   score = col_double()
## )</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(df)</code></pre></div>
<pre><code>## # A tibble: 6 x 3
##   subject  time score
##   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;
## 1 1A        5.5   3  
## 2 2B        2.4   6.9
## 3 3C        8.8  17.9
## 4 4D        7    10.5
## 5 5E        9.3  12.2
## 6 6F        2.5   3.5</code></pre>
<p>If we make a scatterplot of the data, we can see that those who spent longer on the task tended to get higher scores:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># scatterplot</span>
<span class="kw">ggplot</span>(df, <span class="kw">aes</span>(<span class="dt">x =</span> time, <span class="dt">y =</span> score)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>() +
<span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se=</span>F)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-80-1.png" width="672" /></p>
<p>Using a standard approach, we could find the correlation of these two variables and run a signficance test using <code>cor.test()</code>. We can see that there is a moderate Pearson's r of <code>r=0.55</code> which is statistically significant (p=0.031).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># regular significance test</span>
<span class="kw">cor.test</span>(df$time,df$score) <span class="co">#r=0.55, p=0.031</span></code></pre></div>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  df$time and df$score
## t = 2.4258, df = 13, p-value = 0.03057
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.0643515 0.8324385
## sample estimates:
##       cor 
## 0.5582129</code></pre>
<p>We could take an alternative tack, and decide to do a permutation test. The idea here is again, how surprising is it to get a correlation of 0.55 with these data? Were there other ways of ordering the <code>x</code> and <code>y</code> variables to get higher correlation coefficients?</p>
<p>Let's look at our <code>y</code> axis variable, the <code>score</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1</span>) <span class="co"># just doing this so all our results look same</span>

df$score  <span class="co"># actual data in order</span></code></pre></div>
<pre><code>##  [1]  3.0  6.9 17.9 10.5 12.2  3.5 11.0  7.6  8.4 13.4 10.1  9.0 10.1 17.7  6.8</code></pre>
<p>This is the original order of the data. If we use <code>sample()</code> we can shuffle the data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sample</span>(df$score)  <span class="co"># actual data but order shuffled</span></code></pre></div>
<pre><code>##  [1] 10.5  3.5  7.6 10.1 17.9  8.4 13.4 17.7 12.2  3.0  6.9 10.1  9.0  6.8 11.0</code></pre>
<p>Let's shuffle the score again, but this time store it in the original dataframe:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df$shuffle1 &lt;-<span class="st"> </span><span class="kw">sample</span>(df$score) <span class="co">#create a new column with shuffled data</span>

df</code></pre></div>
<pre><code>## # A tibble: 15 x 4
##    subject  time score shuffle1
##    &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;
##  1 1A        5.5   3        7.6
##  2 2B        2.4   6.9     10.1
##  3 3C        8.8  17.9     10.1
##  4 4D        7    10.5     12.2
##  5 5E        9.3  12.2      8.4
##  6 6F        2.5   3.5     13.4
##  7 7G        4.8  11        6.9
##  8 8H        4.1   7.6      3.5
##  9 9I        5     8.4      3  
## 10 10J       2.9  13.4     17.7
## 11 11K       6.4  10.1      6.8
## 12 12L       7.7   9       11  
## 13 13M       9.3  10.1      9  
## 14 14N       8.3  17.7     17.9
## 15 15O       5.1   6.8     10.5</code></pre>
<p>If we plot this shuffled <code>y</code> (score) against the original <code>x</code> (time), we now get this scatterplot, which basically shows no relationship:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># this is what that new column looks like:</span>
<span class="kw">ggplot</span>(df, <span class="kw">aes</span>(<span class="dt">x =</span> time, <span class="dt">y =</span> shuffle1)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>() +
<span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se=</span>F)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-85-1.png" width="672" /></p>
<p>And the correlation for this new scatterplot is really close to 0! r = 0.0005:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor.test</span>(df$time, df$shuffle1) <span class="co"># now relationship is a bit negative</span></code></pre></div>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  df$time and df$shuffle1
## t = 0.0016429, df = 13, p-value = 0.9987
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.5119267  0.5125988
## sample estimates:
##          cor 
## 0.0004556502</code></pre>
<p>We could shuffle the score variable even more times, and directly calculate the <code>r</code> value aginst the time variable for each shuffle using <code>cor()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># we can do this many times</span>
<span class="kw">cor</span>(df$time, <span class="kw">sample</span>(df$score)) <span class="co"># r = 0.35</span></code></pre></div>
<pre><code>## [1] 0.3023584</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(df$time, <span class="kw">sample</span>(df$score)) <span class="co"># r = 0.04</span></code></pre></div>
<pre><code>## [1] -0.05905503</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(df$time, <span class="kw">sample</span>(df$score)) <span class="co"># r = -0.06</span></code></pre></div>
<pre><code>## [1] -0.4665168</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(df$time, <span class="kw">sample</span>(df$score)) <span class="co"># r = 0.15</span></code></pre></div>
<pre><code>## [1] -0.435933</code></pre>
<p>As you can see, the more shuffles we do, we get varied values of <code>r</code>. What we really should do is perform 10,000 (or another really high number) shuffles of the score variable and re-calculate <code>r</code> against the time variable for all 10,000 of these shuffles. Don't worry about the code below, but that's exactly what we're doing. We're saving the <code>r</code> values from the 10,000 shuffles in the object called <code>results</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">results &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&#39;list&#39;</span>,<span class="dv">10000</span>)
for(i in <span class="dv">1</span>:<span class="dv">10000</span>){
  results[[i]] &lt;-<span class="st"> </span><span class="kw">cor</span>(df$time, <span class="kw">sample</span>(df$score))
}

<span class="kw">head</span>(<span class="kw">unlist</span>(results)) <span class="co"># this are the correlations for the first 6 of  10,000 shuffles</span></code></pre></div>
<pre><code>## [1]  0.274190962  0.005288304 -0.114492469 -0.280528642  0.235874922
## [6]  0.061278049</code></pre>
<p>We can plot the results in a histogram, and also put a vertical line at 0.56 which was our original observed correlation between time and score from the raw unshuffled data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">results.df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x =</span> <span class="kw">unlist</span>(results))

<span class="kw">ggplot</span>(results.df, <span class="kw">aes</span>(x)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&quot;darkgreen&quot;</span>,<span class="dt">fill=</span><span class="st">&quot;lightseagreen&quot;</span>) +
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="fl">0.56</span>, <span class="dt">lwd=</span><span class="dv">1</span>, <span class="dt">lty=</span><span class="dv">2</span>) +
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;r&quot;</span>) </code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-89-1.png" width="672" /></p>
<p>As you can see, there were a few shuffles (or permutations) that we got an <code>r</code> value of greater than 0.56, but not that many. In fact, we can directly calculate how many:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(<span class="kw">unlist</span>(results) &gt;<span class="st"> </span><span class="fl">0.56</span>) <span class="co">#163 were greater.</span></code></pre></div>
<pre><code>## [1] 163</code></pre>
<p>It turns out that 163 times out of 10,000 shuffles we got a <code>r</code> value of greater than 0.56. WE could calculate this as a proportion by dividing by 10,000:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(<span class="kw">unlist</span>(results) &gt;<span class="st"> </span><span class="fl">0.56</span>)  /<span class="st"> </span><span class="dv">10000</span>  <span class="co">#0.0163</span></code></pre></div>
<pre><code>## [1] 0.0163</code></pre>
<p>We can use this value as our p-value. Because it is relatively low, we could argue that we were very unlikely by chance alone to have got a <code>r</code> value of 0.56 from our data. This suggests that the correlation between time and score is significant.</p>
<p>The advantages of running a permutation test is that it is free of the assumptions of normality for the Pearson's r correlation signifiance test. It's also a cool method, and pretty intuitive.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="regression.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
