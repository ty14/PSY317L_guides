<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>7 Distributions | PSY317L Guidebook</title>
  <meta name="description" content="7 Distributions | PSY317L Guidebook" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="7 Distributions | PSY317L Guidebook" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="7 Distributions | PSY317L Guidebook" />
  
  
  

<meta name="author" content="James P. Curley &amp; Tyler M. Milewski" />


<meta name="date" content="2020-08-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="descriptives.html"/>
<link rel="next" href="confidence-intervals.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Welcome to PSY317!</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#what-this-book-includes-and-what-it-doesnt"><i class="fa fa-check"></i><b>1.1</b> What this book includes and what it doesn’t</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#how-to-use-this-guide"><i class="fa fa-check"></i><b>1.2</b> How to use this guide</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i><b>1.3</b> Acknowledgements</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#references"><i class="fa fa-check"></i><b>1.4</b> References</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#other-places-to-find-help-about-r-and-statistics"><i class="fa fa-check"></i><b>1.5</b> Other places to find help about R and Statistics</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#downloading-r"><i class="fa fa-check"></i><b>2.1</b> Downloading R</a></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#downloading-rstudio"><i class="fa fa-check"></i><b>2.2</b> Downloading RStudio</a><ul>
<li class="chapter" data-level="2.2.1" data-path="introduction.html"><a href="introduction.html#successful-installation"><i class="fa fa-check"></i><b>2.2.1</b> Successful installation</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#using-rcloud"><i class="fa fa-check"></i><b>2.3</b> Using RCloud</a></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#the-rstudio-environment"><i class="fa fa-check"></i><b>2.4</b> The RStudio Environment</a></li>
<li class="chapter" data-level="2.5" data-path="introduction.html"><a href="introduction.html#running-code"><i class="fa fa-check"></i><b>2.5</b> Running Code</a><ul>
<li class="chapter" data-level="2.5.1" data-path="introduction.html"><a href="introduction.html#the-console"><i class="fa fa-check"></i><b>2.5.1</b> The Console</a></li>
<li class="chapter" data-level="2.5.2" data-path="introduction.html"><a href="introduction.html#rscript"><i class="fa fa-check"></i><b>2.5.2</b> RScript</a></li>
<li class="chapter" data-level="2.5.3" data-path="introduction.html"><a href="introduction.html#saving-an-rscript"><i class="fa fa-check"></i><b>2.5.3</b> Saving an RScript</a></li>
<li class="chapter" data-level="2.5.4" data-path="introduction.html"><a href="introduction.html#open-an-existing-rscript"><i class="fa fa-check"></i><b>2.5.4</b> Open an existing RScript</a></li>
<li class="chapter" data-level="2.5.5" data-path="introduction.html"><a href="introduction.html#running-code-in-scripts"><i class="fa fa-check"></i><b>2.5.5</b> Running Code in Scripts</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="introduction.html"><a href="introduction.html#packages"><i class="fa fa-check"></i><b>2.6</b> Packages</a></li>
<li class="chapter" data-level="2.7" data-path="introduction.html"><a href="introduction.html#working-with-rstudio-in-psy317l"><i class="fa fa-check"></i><b>2.7</b> Working with RStudio in PSY317L</a></li>
<li class="chapter" data-level="2.8" data-path="introduction.html"><a href="introduction.html#quitting-rstudio"><i class="fa fa-check"></i><b>2.8</b> Quitting RStudio</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="basic-syntax.html"><a href="basic-syntax.html"><i class="fa fa-check"></i><b>3</b> Basic Syntax</a><ul>
<li class="chapter" data-level="3.1" data-path="basic-syntax.html"><a href="basic-syntax.html#simple-mathematical-syntax"><i class="fa fa-check"></i><b>3.1</b> Simple mathematical syntax</a></li>
<li class="chapter" data-level="3.2" data-path="basic-syntax.html"><a href="basic-syntax.html#assignment"><i class="fa fa-check"></i><b>3.2</b> Assignment</a></li>
<li class="chapter" data-level="3.3" data-path="basic-syntax.html"><a href="basic-syntax.html#vectors"><i class="fa fa-check"></i><b>3.3</b> Vectors</a></li>
<li class="chapter" data-level="3.4" data-path="basic-syntax.html"><a href="basic-syntax.html#characters"><i class="fa fa-check"></i><b>3.4</b> Characters</a></li>
<li class="chapter" data-level="3.5" data-path="basic-syntax.html"><a href="basic-syntax.html#naming-of-objects"><i class="fa fa-check"></i><b>3.5</b> Naming of objects</a></li>
<li class="chapter" data-level="3.6" data-path="basic-syntax.html"><a href="basic-syntax.html#logical-operators"><i class="fa fa-check"></i><b>3.6</b> Logical Operators</a></li>
<li class="chapter" data-level="3.7" data-path="basic-syntax.html"><a href="basic-syntax.html#some-things-that-are-useful-to-know."><i class="fa fa-check"></i><b>3.7</b> Some things that are useful to know.</a><ul>
<li class="chapter" data-level="3.7.1" data-path="basic-syntax.html"><a href="basic-syntax.html#tab-is-your-friend"><i class="fa fa-check"></i><b>3.7.1</b> Tab is your friend</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="basic-syntax.html"><a href="basic-syntax.html#error-messages"><i class="fa fa-check"></i><b>3.8</b> Error Messages</a></li>
<li class="chapter" data-level="3.9" data-path="basic-syntax.html"><a href="basic-syntax.html#functions"><i class="fa fa-check"></i><b>3.9</b> Functions</a></li>
<li class="chapter" data-level="3.10" data-path="basic-syntax.html"><a href="basic-syntax.html#chaining-syntax"><i class="fa fa-check"></i><b>3.10</b> Chaining Syntax</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html"><i class="fa fa-check"></i><b>4</b> Introduction to Data Carpentry</a><ul>
<li class="chapter" data-level="4.1" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#data-types"><i class="fa fa-check"></i><b>4.1</b> Data Types</a><ul>
<li class="chapter" data-level="4.1.1" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#categorical-data"><i class="fa fa-check"></i><b>4.1.1</b> Categorical Data</a></li>
<li class="chapter" data-level="4.1.2" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#numerical-data-discrete-vs.-continuous"><i class="fa fa-check"></i><b>4.1.2</b> Numerical Data (Discrete vs. Continuous)</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#importing-data"><i class="fa fa-check"></i><b>4.2</b> Importing Data</a></li>
<li class="chapter" data-level="4.3" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#introduction-to-dataframes"><i class="fa fa-check"></i><b>4.3</b> Introduction to Dataframes</a><ul>
<li class="chapter" data-level="4.3.1" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#dataframe-basics"><i class="fa fa-check"></i><b>4.3.1</b> Dataframe basics</a></li>
<li class="chapter" data-level="4.3.2" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#indexing-dataframes."><i class="fa fa-check"></i><b>4.3.2</b> Indexing dataframes.</a></li>
<li class="chapter" data-level="4.3.3" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#adding-and-removing-columns"><i class="fa fa-check"></i><b>4.3.3</b> Adding and removing columns</a></li>
<li class="chapter" data-level="4.3.4" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#structure-of-datasets"><i class="fa fa-check"></i><b>4.3.4</b> Structure of Datasets</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#manually-creating-a-dataframe"><i class="fa fa-check"></i><b>4.4</b> Manually creating a Dataframe</a></li>
<li class="chapter" data-level="4.5" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#tidyverse"><i class="fa fa-check"></i><b>4.5</b> tidyverse</a><ul>
<li class="chapter" data-level="4.5.1" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#table"><i class="fa fa-check"></i><b>4.5.1</b> table()</a></li>
<li class="chapter" data-level="4.5.2" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#filter---subsetting-data"><i class="fa fa-check"></i><b>4.5.2</b> filter() - Subsetting Data</a></li>
<li class="chapter" data-level="4.5.3" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#select---selecting-specific-columns"><i class="fa fa-check"></i><b>4.5.3</b> select() - Selecting specific columns</a></li>
<li class="chapter" data-level="4.5.4" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#mutate---creating-new-columns"><i class="fa fa-check"></i><b>4.5.4</b> mutate() - Creating new columns</a></li>
<li class="chapter" data-level="4.5.5" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#arrange---sort-data-columns"><i class="fa fa-check"></i><b>4.5.5</b> arrange() - Sort Data Columns</a></li>
<li class="chapter" data-level="4.5.6" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#chaining-together"><i class="fa fa-check"></i><b>4.5.6</b> Chaining together</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#wide-versus-long-data"><i class="fa fa-check"></i><b>4.6</b> Wide versus Long Data</a><ul>
<li class="chapter" data-level="4.6.1" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#wide-to-long"><i class="fa fa-check"></i><b>4.6.1</b> Wide to Long</a></li>
<li class="chapter" data-level="4.6.2" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#long-to-wide"><i class="fa fa-check"></i><b>4.6.2</b> Long to Wide</a></li>
<li class="chapter" data-level="4.6.3" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#real-data-example."><i class="fa fa-check"></i><b>4.6.3</b> Real Data Example.</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="introduction-to-data-carpentry.html"><a href="introduction-to-data-carpentry.html#joins"><i class="fa fa-check"></i><b>4.7</b> Joins</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="data-visualization.html"><a href="data-visualization.html"><i class="fa fa-check"></i><b>5</b> Data Visualization</a><ul>
<li class="chapter" data-level="5.1" data-path="data-visualization.html"><a href="data-visualization.html#introduction-to-ggplot2"><i class="fa fa-check"></i><b>5.1</b> Introduction to ggplot2</a><ul>
<li class="chapter" data-level="5.1.1" data-path="data-visualization.html"><a href="data-visualization.html#assigning-plots"><i class="fa fa-check"></i><b>5.1.1</b> Assigning plots</a></li>
<li class="chapter" data-level="5.1.2" data-path="data-visualization.html"><a href="data-visualization.html#titles-and-axes-titles"><i class="fa fa-check"></i><b>5.1.2</b> Titles and Axes Titles</a></li>
<li class="chapter" data-level="5.1.3" data-path="data-visualization.html"><a href="data-visualization.html#colors-shapes-and-sizes"><i class="fa fa-check"></i><b>5.1.3</b> Colors, Shapes and Sizes</a></li>
<li class="chapter" data-level="5.1.4" data-path="data-visualization.html"><a href="data-visualization.html#themes"><i class="fa fa-check"></i><b>5.1.4</b> Themes</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="data-visualization.html"><a href="data-visualization.html#histograms"><i class="fa fa-check"></i><b>5.2</b> Histograms</a><ul>
<li class="chapter" data-level="5.2.1" data-path="data-visualization.html"><a href="data-visualization.html#histograms-with-ggplot2"><i class="fa fa-check"></i><b>5.2.1</b> Histograms with ggplot2</a></li>
<li class="chapter" data-level="5.2.2" data-path="data-visualization.html"><a href="data-visualization.html#density-curves"><i class="fa fa-check"></i><b>5.2.2</b> Density Curves</a></li>
<li class="chapter" data-level="5.2.3" data-path="data-visualization.html"><a href="data-visualization.html#comparing-distributions"><i class="fa fa-check"></i><b>5.2.3</b> Comparing Distributions</a></li>
<li class="chapter" data-level="5.2.4" data-path="data-visualization.html"><a href="data-visualization.html#stem-and-leaf-plots"><i class="fa fa-check"></i><b>5.2.4</b> Stem-and-Leaf Plots</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="data-visualization.html"><a href="data-visualization.html#scatterplots"><i class="fa fa-check"></i><b>5.3</b> Scatterplots</a><ul>
<li class="chapter" data-level="5.3.1" data-path="data-visualization.html"><a href="data-visualization.html#bubble-charts"><i class="fa fa-check"></i><b>5.3.1</b> Bubble Charts</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="data-visualization.html"><a href="data-visualization.html#line-graphs"><i class="fa fa-check"></i><b>5.4</b> Line Graphs</a><ul>
<li class="chapter" data-level="5.4.1" data-path="data-visualization.html"><a href="data-visualization.html#multiple-line-graphs"><i class="fa fa-check"></i><b>5.4.1</b> Multiple Line Graphs</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="data-visualization.html"><a href="data-visualization.html#comparing-distributions-across-groups"><i class="fa fa-check"></i><b>5.5</b> Comparing Distributions across Groups</a><ul>
<li class="chapter" data-level="5.5.1" data-path="data-visualization.html"><a href="data-visualization.html#strip-plots"><i class="fa fa-check"></i><b>5.5.1</b> Strip Plots</a></li>
<li class="chapter" data-level="5.5.2" data-path="data-visualization.html"><a href="data-visualization.html#boxplots"><i class="fa fa-check"></i><b>5.5.2</b> Boxplots</a></li>
<li class="chapter" data-level="5.5.3" data-path="data-visualization.html"><a href="data-visualization.html#violin-plots"><i class="fa fa-check"></i><b>5.5.3</b> Violin Plots</a></li>
<li class="chapter" data-level="5.5.4" data-path="data-visualization.html"><a href="data-visualization.html#stacked-boxplots"><i class="fa fa-check"></i><b>5.5.4</b> Stacked Boxplots</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="data-visualization.html"><a href="data-visualization.html#bar-graphs"><i class="fa fa-check"></i><b>5.6</b> Bar Graphs</a></li>
<li class="chapter" data-level="5.7" data-path="data-visualization.html"><a href="data-visualization.html#small-multiples"><i class="fa fa-check"></i><b>5.7</b> Small Multiples</a></li>
<li class="chapter" data-level="5.8" data-path="data-visualization.html"><a href="data-visualization.html#saving-and-exporting-ggplot2-graphs"><i class="fa fa-check"></i><b>5.8</b> Saving and Exporting ggplot2 graphs</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="descriptives.html"><a href="descriptives.html"><i class="fa fa-check"></i><b>6</b> Descriptives</a><ul>
<li class="chapter" data-level="6.1" data-path="descriptives.html"><a href="descriptives.html#sample-vs-population"><i class="fa fa-check"></i><b>6.1</b> Sample vs Population</a></li>
<li class="chapter" data-level="6.2" data-path="descriptives.html"><a href="descriptives.html#sample-and-population-size"><i class="fa fa-check"></i><b>6.2</b> Sample and Population Size</a></li>
<li class="chapter" data-level="6.3" data-path="descriptives.html"><a href="descriptives.html#central-tendency"><i class="fa fa-check"></i><b>6.3</b> Central Tendency</a><ul>
<li class="chapter" data-level="6.3.1" data-path="descriptives.html"><a href="descriptives.html#mode"><i class="fa fa-check"></i><b>6.3.1</b> Mode</a></li>
<li class="chapter" data-level="6.3.2" data-path="descriptives.html"><a href="descriptives.html#median"><i class="fa fa-check"></i><b>6.3.2</b> Median</a></li>
<li class="chapter" data-level="6.3.3" data-path="descriptives.html"><a href="descriptives.html#mean"><i class="fa fa-check"></i><b>6.3.3</b> Mean</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="descriptives.html"><a href="descriptives.html#variation"><i class="fa fa-check"></i><b>6.4</b> Variation</a><ul>
<li class="chapter" data-level="6.4.1" data-path="descriptives.html"><a href="descriptives.html#range"><i class="fa fa-check"></i><b>6.4.1</b> Range</a></li>
<li class="chapter" data-level="6.4.2" data-path="descriptives.html"><a href="descriptives.html#interquartile-range"><i class="fa fa-check"></i><b>6.4.2</b> Interquartile Range</a></li>
<li class="chapter" data-level="6.4.3" data-path="descriptives.html"><a href="descriptives.html#average-deviation"><i class="fa fa-check"></i><b>6.4.3</b> Average Deviation</a></li>
<li class="chapter" data-level="6.4.4" data-path="descriptives.html"><a href="descriptives.html#standard-deviation"><i class="fa fa-check"></i><b>6.4.4</b> Standard Deviation</a></li>
<li class="chapter" data-level="6.4.5" data-path="descriptives.html"><a href="descriptives.html#variance"><i class="fa fa-check"></i><b>6.4.5</b> Variance</a></li>
<li class="chapter" data-level="6.4.6" data-path="descriptives.html"><a href="descriptives.html#average-versus-standard-deviation"><i class="fa fa-check"></i><b>6.4.6</b> Average versus Standard Deviation</a></li>
<li class="chapter" data-level="6.4.7" data-path="descriptives.html"><a href="descriptives.html#sample-standard-deviation"><i class="fa fa-check"></i><b>6.4.7</b> Sample Standard Deviation</a></li>
<li class="chapter" data-level="6.4.8" data-path="descriptives.html"><a href="descriptives.html#sample-versus-population-standard-deviation"><i class="fa fa-check"></i><b>6.4.8</b> Sample versus Population Standard Deviation</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="descriptives.html"><a href="descriptives.html#descriptive-statistics-in-r"><i class="fa fa-check"></i><b>6.5</b> Descriptive Statistics in R</a><ul>
<li class="chapter" data-level="6.5.1" data-path="descriptives.html"><a href="descriptives.html#dealing-with-missing-data"><i class="fa fa-check"></i><b>6.5.1</b> Dealing with Missing Data</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="descriptives.html"><a href="descriptives.html#descriptives-for-datasets"><i class="fa fa-check"></i><b>6.6</b> Descriptives for Datasets</a><ul>
<li class="chapter" data-level="6.6.1" data-path="descriptives.html"><a href="descriptives.html#descriptives-for-groups"><i class="fa fa-check"></i><b>6.6.1</b> Descriptives for Groups</a></li>
<li class="chapter" data-level="6.6.2" data-path="descriptives.html"><a href="descriptives.html#counts-by-group"><i class="fa fa-check"></i><b>6.6.2</b> Counts by Group</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>7</b> Distributions</a><ul>
<li class="chapter" data-level="7.0.1" data-path="distributions.html"><a href="distributions.html#uniform-distribution"><i class="fa fa-check"></i><b>7.0.1</b> Uniform Distribution</a></li>
<li class="chapter" data-level="7.0.2" data-path="distributions.html"><a href="distributions.html#bimodal-distribution"><i class="fa fa-check"></i><b>7.0.2</b> Bimodal Distribution</a></li>
<li class="chapter" data-level="7.0.3" data-path="distributions.html"><a href="distributions.html#normal-distribution"><i class="fa fa-check"></i><b>7.0.3</b> Normal Distribution</a></li>
<li class="chapter" data-level="7.0.4" data-path="distributions.html"><a href="distributions.html#standard-normal-distribution"><i class="fa fa-check"></i><b>7.0.4</b> Standard Normal Distribution</a></li>
<li class="chapter" data-level="7.0.5" data-path="distributions.html"><a href="distributions.html#skewness-and-kurtosis"><i class="fa fa-check"></i><b>7.0.5</b> Skewness and Kurtosis</a></li>
<li class="chapter" data-level="7.1" data-path="distributions.html"><a href="distributions.html#z-scores"><i class="fa fa-check"></i><b>7.1</b> Z-scores</a><ul>
<li class="chapter" data-level="7.1.1" data-path="distributions.html"><a href="distributions.html#z-scores-in-samples."><i class="fa fa-check"></i><b>7.1.1</b> z-scores in samples.</a></li>
<li class="chapter" data-level="7.1.2" data-path="distributions.html"><a href="distributions.html#using-z-scores-to-determine-probabilities"><i class="fa fa-check"></i><b>7.1.2</b> Using z-scores to determine probabilities</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="distributions.html"><a href="distributions.html#what-is-a-sampling-distribution"><i class="fa fa-check"></i><b>7.2</b> What is a Sampling Distribution ?</a><ul>
<li class="chapter" data-level="7.2.1" data-path="distributions.html"><a href="distributions.html#sample-size-and-the-sampling-distribution"><i class="fa fa-check"></i><b>7.2.1</b> Sample Size and the Sampling Distribution</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="distributions.html"><a href="distributions.html#central-limit-theorem"><i class="fa fa-check"></i><b>7.3</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="7.4" data-path="distributions.html"><a href="distributions.html#sampling-distribution-problems"><i class="fa fa-check"></i><b>7.4</b> Sampling distribution problems</a></li>
<li class="chapter" data-level="7.5" data-path="distributions.html"><a href="distributions.html#the-t-distribution"><i class="fa fa-check"></i><b>7.5</b> The t-distribution</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="confidence-intervals.html"><a href="confidence-intervals.html"><i class="fa fa-check"></i><b>8</b> Confidence Intervals</a><ul>
<li class="chapter" data-level="8.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#sample-means-as-estimates."><i class="fa fa-check"></i><b>8.1</b> Sample means as estimates.</a></li>
<li class="chapter" data-level="8.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#calculating-a-confidence-interval-with-z-distribution"><i class="fa fa-check"></i><b>8.2</b> Calculating a confidence interval with z-distribution</a><ul>
<li class="chapter" data-level="8.2.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#other-confidence-intervals-ranges"><i class="fa fa-check"></i><b>8.2.1</b> Other Confidence Intervals ranges</a></li>
<li class="chapter" data-level="8.2.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#confidence-intervals-and-sample-size"><i class="fa fa-check"></i><b>8.2.2</b> Confidence Intervals and Sample Size</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#confidence-intervals-with-t-distribution"><i class="fa fa-check"></i><b>8.3</b> Confidence Intervals with t-distribution</a></li>
<li class="chapter" data-level="8.4" data-path="confidence-intervals.html"><a href="confidence-intervals.html#calculating-a-t-distribution-confidence-interval"><i class="fa fa-check"></i><b>8.4</b> Calculating a t-distribution Confidence Interval</a><ul>
<li class="chapter" data-level="8.4.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#t-distribution-cis-and-sample-size."><i class="fa fa-check"></i><b>8.4.1</b> t-distribution CIs and sample size.</a></li>
<li class="chapter" data-level="8.4.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#other-confidence-intervals-ranges-for-t-distribution"><i class="fa fa-check"></i><b>8.4.2</b> Other Confidence Intervals ranges for t-distribution</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="confidence-intervals.html"><a href="confidence-intervals.html#comparing-cis-using-the-z--and-t-distributions"><i class="fa fa-check"></i><b>8.5</b> Comparing CIs using the z- and t-distributions</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="one-sample-inferential-statistics.html"><a href="one-sample-inferential-statistics.html"><i class="fa fa-check"></i><b>9</b> One Sample Inferential Statistics</a><ul>
<li class="chapter" data-level="9.1" data-path="one-sample-inferential-statistics.html"><a href="one-sample-inferential-statistics.html#one-sample-z-tests"><i class="fa fa-check"></i><b>9.1</b> One-sample z-tests</a><ul>
<li class="chapter" data-level="9.1.1" data-path="one-sample-inferential-statistics.html"><a href="one-sample-inferential-statistics.html#sampling-distribution-recap"><i class="fa fa-check"></i><b>9.1.1</b> Sampling Distribution Recap</a></li>
<li class="chapter" data-level="9.1.2" data-path="one-sample-inferential-statistics.html"><a href="one-sample-inferential-statistics.html#calculating-p-values-for-z-test"><i class="fa fa-check"></i><b>9.1.2</b> Calculating p-values for z-test</a></li>
<li class="chapter" data-level="9.1.3" data-path="one-sample-inferential-statistics.html"><a href="one-sample-inferential-statistics.html#using-critical-values"><i class="fa fa-check"></i><b>9.1.3</b> Using critical values</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="one-sample-inferential-statistics.html"><a href="one-sample-inferential-statistics.html#one-sample-t-tests"><i class="fa fa-check"></i><b>9.2</b> One-sample t-tests</a><ul>
<li class="chapter" data-level="9.2.1" data-path="one-sample-inferential-statistics.html"><a href="one-sample-inferential-statistics.html#critical-values-for-the-one-sample-t-test"><i class="fa fa-check"></i><b>9.2.1</b> Critical values for the one-sample t-test</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="one-sample-inferential-statistics.html"><a href="one-sample-inferential-statistics.html#conducting-one-sample-t-tests-in-r"><i class="fa fa-check"></i><b>9.3</b> Conducting one-sample t-tests in R</a></li>
<li class="chapter" data-level="9.4" data-path="one-sample-inferential-statistics.html"><a href="one-sample-inferential-statistics.html#assumptions-of-the-one-sample-t-test"><i class="fa fa-check"></i><b>9.4</b> Assumptions of the one-sample t-test</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html"><i class="fa fa-check"></i><b>10</b> Two Sample Inferential Statistics</a><ul>
<li class="chapter" data-level="10.1" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#independent-samples-t-test"><i class="fa fa-check"></i><b>10.1</b> Independent Samples t-test</a></li>
<li class="chapter" data-level="10.2" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#sampling-distribution-of-the-difference-in-sample-means"><i class="fa fa-check"></i><b>10.2</b> Sampling Distribution of the Difference in Sample Means</a><ul>
<li class="chapter" data-level="10.2.1" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#visualizing-the-sampling-distribution"><i class="fa fa-check"></i><b>10.2.1</b> Visualizing the Sampling Distribution</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#pooled-standard-deviation"><i class="fa fa-check"></i><b>10.3</b> Pooled Standard Deviation</a></li>
<li class="chapter" data-level="10.4" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#theory-behind-students-t-test"><i class="fa fa-check"></i><b>10.4</b> Theory behind Student’s t-test</a></li>
<li class="chapter" data-level="10.5" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#confidence-interval-for-difference-in-means"><i class="fa fa-check"></i><b>10.5</b> Confidence Interval for Difference in Means</a></li>
<li class="chapter" data-level="10.6" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#conducting-the-student-t-test-in-r"><i class="fa fa-check"></i><b>10.6</b> Conducting the Student t-test in R</a></li>
<li class="chapter" data-level="10.7" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#assumptions-of-the-independent-t-test"><i class="fa fa-check"></i><b>10.7</b> Assumptions of the Independent t-test</a></li>
<li class="chapter" data-level="10.8" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#welchs-t-test"><i class="fa fa-check"></i><b>10.8</b> Welch’s t-test</a></li>
<li class="chapter" data-level="10.9" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#effect-size-for-independent-two-sample-t-tests"><i class="fa fa-check"></i><b>10.9</b> Effect Size for Independent two sample t-tests:</a></li>
<li class="chapter" data-level="10.10" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#paired-t-tests"><i class="fa fa-check"></i><b>10.10</b> Paired t-tests</a><ul>
<li class="chapter" data-level="10.10.1" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#the-paired-t-test-is-a-one-sample-t-test"><i class="fa fa-check"></i><b>10.10.1</b> The paired t-test is a one-sample t-test</a></li>
<li class="chapter" data-level="10.10.2" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#one-tailed-paired-t-tests"><i class="fa fa-check"></i><b>10.10.2</b> One-tailed paired t-tests</a></li>
<li class="chapter" data-level="10.10.3" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#calculating-effect-sizes"><i class="fa fa-check"></i><b>10.10.3</b> Calculating effect sizes</a></li>
</ul></li>
<li class="chapter" data-level="10.11" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#non-parametric-alternatives-for-independent-t-tests"><i class="fa fa-check"></i><b>10.11</b> Non-parametric Alternatives for Independent t-tests</a></li>
<li class="chapter" data-level="10.12" data-path="two-sample-inferential-statistics.html"><a href="two-sample-inferential-statistics.html#non-parametric-alternatives-to-the-two-sample-t-tests"><i class="fa fa-check"></i><b>10.12</b> Non-parametric Alternatives to the Two Sample t-tests</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="correlation.html"><a href="correlation.html"><i class="fa fa-check"></i><b>11</b> Correlation</a><ul>
<li class="chapter" data-level="11.1" data-path="correlation.html"><a href="correlation.html#pearson-correlation"><i class="fa fa-check"></i><b>11.1</b> Pearson Correlation</a></li>
<li class="chapter" data-level="11.2" data-path="correlation.html"><a href="correlation.html#cross-products"><i class="fa fa-check"></i><b>11.2</b> Cross-products</a></li>
<li class="chapter" data-level="11.3" data-path="correlation.html"><a href="correlation.html#conducting-a-pearson-correlation-test"><i class="fa fa-check"></i><b>11.3</b> Conducting a Pearson Correlation Test</a></li>
<li class="chapter" data-level="11.4" data-path="correlation.html"><a href="correlation.html#assumptions-of-pearsons-correlation"><i class="fa fa-check"></i><b>11.4</b> Assumptions of Pearson’s Correlation</a></li>
<li class="chapter" data-level="11.5" data-path="correlation.html"><a href="correlation.html#confidence-intervals-for-r"><i class="fa fa-check"></i><b>11.5</b> Confidence Intervals for r</a></li>
<li class="chapter" data-level="11.6" data-path="correlation.html"><a href="correlation.html#partial-correlations"><i class="fa fa-check"></i><b>11.6</b> Partial Correlations</a></li>
<li class="chapter" data-level="11.7" data-path="correlation.html"><a href="correlation.html#non-parametric-correlations"><i class="fa fa-check"></i><b>11.7</b> Non-parametric Correlations</a></li>
<li class="chapter" data-level="11.8" data-path="correlation.html"><a href="correlation.html#point-biserial-correlation"><i class="fa fa-check"></i><b>11.8</b> Point-Biserial Correlation</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>12</b> Linear Regression</a><ul>
<li class="chapter" data-level="12.1" data-path="linear-regression.html"><a href="linear-regression.html#introduction-to-linear-regression"><i class="fa fa-check"></i><b>12.1</b> Introduction to Linear Regression</a></li>
<li class="chapter" data-level="12.2" data-path="linear-regression.html"><a href="linear-regression.html#a-and-b"><i class="fa fa-check"></i><b>12.2</b> a and b</a><ul>
<li class="chapter" data-level="12.2.1" data-path="linear-regression.html"><a href="linear-regression.html#how-to-calculate-a-and-b-in-r"><i class="fa fa-check"></i><b>12.2.1</b> How to calculate a and b in R</a></li>
<li class="chapter" data-level="12.2.2" data-path="linear-regression.html"><a href="linear-regression.html#how-to-calculate-a-and-b-by-hand"><i class="fa fa-check"></i><b>12.2.2</b> How to calculate a and b ‘by hand’</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="linear-regression.html"><a href="linear-regression.html#residuals"><i class="fa fa-check"></i><b>12.3</b> Residuals</a><ul>
<li class="chapter" data-level="12.3.1" data-path="linear-regression.html"><a href="linear-regression.html#how-to-calculate-the-residuals"><i class="fa fa-check"></i><b>12.3.1</b> How to calculate the residuals</a></li>
<li class="chapter" data-level="12.3.2" data-path="linear-regression.html"><a href="linear-regression.html#visualizing-the-residuals"><i class="fa fa-check"></i><b>12.3.2</b> Visualizing the Residuals</a></li>
<li class="chapter" data-level="12.3.3" data-path="linear-regression.html"><a href="linear-regression.html#comparing-our-trendline-to-other-trendlines"><i class="fa fa-check"></i><b>12.3.3</b> Comparing our trendline to other trendlines</a></li>
<li class="chapter" data-level="12.3.4" data-path="linear-regression.html"><a href="linear-regression.html#coefficient-of-determination-r2"><i class="fa fa-check"></i><b>12.3.4</b> Coefficient of Determination R2</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="linear-regression.html"><a href="linear-regression.html#standard-error-of-the-estimate"><i class="fa fa-check"></i><b>12.4</b> Standard Error of the Estimate</a><ul>
<li class="chapter" data-level="12.4.1" data-path="linear-regression.html"><a href="linear-regression.html#what-to-do-with-the-standard-error-of-the-estimate"><i class="fa fa-check"></i><b>12.4.1</b> What to do with the Standard Error of the Estimate ?</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="linear-regression.html"><a href="linear-regression.html#goodness-of-fit-test---f-ratio"><i class="fa fa-check"></i><b>12.5</b> Goodness of Fit Test - F-ratio</a></li>
<li class="chapter" data-level="12.6" data-path="linear-regression.html"><a href="linear-regression.html#assumptions-of-linear-regression"><i class="fa fa-check"></i><b>12.6</b> Assumptions of Linear Regression</a><ul>
<li class="chapter" data-level="12.6.1" data-path="linear-regression.html"><a href="linear-regression.html#normality-of-residuals"><i class="fa fa-check"></i><b>12.6.1</b> Normality of Residuals</a></li>
<li class="chapter" data-level="12.6.2" data-path="linear-regression.html"><a href="linear-regression.html#linearity"><i class="fa fa-check"></i><b>12.6.2</b> 2. Linearity —</a></li>
<li class="chapter" data-level="12.6.3" data-path="linear-regression.html"><a href="linear-regression.html#homogeneity-of-variance-homoscedasticity"><i class="fa fa-check"></i><b>12.6.3</b> 3. Homogeneity of Variance / Homoscedasticity</a></li>
<li class="chapter" data-level="12.6.4" data-path="linear-regression.html"><a href="linear-regression.html#no-colinearity"><i class="fa fa-check"></i><b>12.6.4</b> No Colinearity</a></li>
<li class="chapter" data-level="12.6.5" data-path="linear-regression.html"><a href="linear-regression.html#unusual-datapoints"><i class="fa fa-check"></i><b>12.6.5</b> Unusual Datapoints</a></li>
</ul></li>
<li class="chapter" data-level="12.7" data-path="linear-regression.html"><a href="linear-regression.html#examining-individual-predictor-estimates"><i class="fa fa-check"></i><b>12.7</b> Examining individual predictor estimates</a><ul>
<li class="chapter" data-level="12.7.1" data-path="linear-regression.html"><a href="linear-regression.html#confidence-interval-of-b."><i class="fa fa-check"></i><b>12.7.1</b> 95% confidence interval of ‘b’.</a></li>
<li class="chapter" data-level="12.7.2" data-path="linear-regression.html"><a href="linear-regression.html#standard-error-of-b"><i class="fa fa-check"></i><b>12.7.2</b> Standard Error of b</a></li>
<li class="chapter" data-level="12.7.3" data-path="linear-regression.html"><a href="linear-regression.html#calculating-95-confidence-interval-of-b-by-hand"><i class="fa fa-check"></i><b>12.7.3</b> Calculating 95% confidence interval of ‘b’ by hand</a></li>
<li class="chapter" data-level="12.7.4" data-path="linear-regression.html"><a href="linear-regression.html#signifcance-testing-b"><i class="fa fa-check"></i><b>12.7.4</b> Signifcance Testing b</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="permutation-testing.html"><a href="permutation-testing.html"><i class="fa fa-check"></i><b>13</b> Permutation Testing</a><ul>
<li class="chapter" data-level="13.1" data-path="permutation-testing.html"><a href="permutation-testing.html#t-test-permutation"><i class="fa fa-check"></i><b>13.1</b> t-test Permutation</a></li>
<li class="chapter" data-level="13.2" data-path="permutation-testing.html"><a href="permutation-testing.html#correlation-coefficient-permutation-tests"><i class="fa fa-check"></i><b>13.2</b> Correlation Coefficient Permutation Tests</a></li>
<li class="chapter" data-level="13.3" data-path="permutation-testing.html"><a href="permutation-testing.html#permutation-test-for-a-paired-t-test"><i class="fa fa-check"></i><b>13.3</b> Permutation test for a Paired t-test</a></li>
<li class="chapter" data-level="13.4" data-path="permutation-testing.html"><a href="permutation-testing.html#permutation-tests-in-packages"><i class="fa fa-check"></i><b>13.4</b> Permutation tests in Packages</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">PSY317L Guidebook</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="distributions" class="section level1">
<h1><span class="header-section-number">7</span> Distributions</h1>
<p>In statistical terms a distribution refers to the range of possible values that can come from a sample space. Another way of stating that is to say that a distribution represents how the probabilities of getting various values are distributed.</p>
<p>There are several classic distributions in statistics. There are distributions such as the normal, t, Poisson, bimodal etc.</p>
<p>We’re going to dig a bit deeper into distributions, in particular the normal distribution. The best way to look at distributions is to plot histograms. Let’s look at some distributions.</p>
<div id="uniform-distribution" class="section level3">
<h3><span class="header-section-number">7.0.1</span> Uniform Distribution</h3>
<p>The first distribution we’ll look at is the uniform. A uniform distribution is one where there’s an equal probability of getting each value from the distribution. In the example below, we’ve grabbed 1,000,000 numbers from a uniform distribution that starts at 0 and ends at 100. Let’s look at it’s shape:</p>
<pre><code>## Warning: package &#39;tidyverse&#39; was built under R version 3.5.3</code></pre>
<pre><code>## -- Attaching packages ----------------------------------------------------------------------------------------------- tidyverse 1.3.0 --</code></pre>
<pre><code>## v ggplot2 3.3.2     v purrr   0.3.4
## v tibble  3.0.3     v dplyr   0.8.3
## v tidyr   1.0.2     v stringr 1.4.0
## v readr   1.3.1     v forcats 0.5.0</code></pre>
<pre><code>## Warning: package &#39;tidyr&#39; was built under R version 3.5.3</code></pre>
<pre><code>## Warning: package &#39;readr&#39; was built under R version 3.5.3</code></pre>
<pre><code>## Warning: package &#39;purrr&#39; was built under R version 3.5.3</code></pre>
<pre><code>## Warning: package &#39;dplyr&#39; was built under R version 3.5.3</code></pre>
<pre><code>## Warning: package &#39;stringr&#39; was built under R version 3.5.3</code></pre>
<pre><code>## Warning: package &#39;forcats&#39; was built under R version 3.5.3</code></pre>
<pre><code>## -- Conflicts -------------------------------------------------------------------------------------------------- tidyverse_conflicts() --
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>As you can see, the histogram that we have generated is roughly flat across the top. This means that we have equal frequency counts in each bin. Each bin here is 5 across, so the first bin is 0-5, the next bin is 5-10, and so on. We have 25 bins in total in this histogram, and each has roughly 50,000 values in it. This is the classic shape of the uniform distribution.</p>
</div>
<div id="bimodal-distribution" class="section level3">
<h3><span class="header-section-number">7.0.2</span> Bimodal Distribution</h3>
<p>Another family of distributions that is worth our attention are bimodal distributions. In these distributions we have two peaks in the distribution. You can see an example below:</p>
<p><img src="_main_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
</div>
<div id="normal-distribution" class="section level3">
<h3><span class="header-section-number">7.0.3</span> Normal Distribution</h3>
<p>In most domains, the type of histograms i.e. distributions, that we most commonly observe don’t have 0 peaks like the uniform distribution or 2 peaks like the bimodal distribution, but have just one peak. These are called <strong>unimodal</strong> distributions. One such classic distribution that is very important to statistics is the normal distribution.</p>
<p>The normal distribution has one peak and is symmetrical, with the same proportion of data on each side of the distribution. In addition, we say that a normal distribution has a <em>skewness of 0</em> and a <em>kurtosis of 3</em>. We’ll talk about what those are a little bit more about what that means very shortly.</p>
<p>Let’s look at a normal distribution. The following normal distribution has a mean of 100 and a standard deviation of 5. We can generate it by collecting 1,000,000 datapoints in R:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="distributions.html#cb11-1"></a><span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb11-2"><a href="distributions.html#cb11-2"></a></span>
<span id="cb11-3"><a href="distributions.html#cb11-3"></a>x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="dv">1000000</span>, <span class="dt">mean =</span> <span class="dv">100</span>, <span class="dt">sd =</span> <span class="fl">5.0</span>)</span>
<span id="cb11-4"><a href="distributions.html#cb11-4"></a></span>
<span id="cb11-5"><a href="distributions.html#cb11-5"></a><span class="kw">mean</span>(x) </span></code></pre></div>
<pre><code>## [1] 100.0002</code></pre>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="distributions.html#cb13-1"></a><span class="kw">sd</span>(x) </span></code></pre></div>
<pre><code>## [1] 5.000926</code></pre>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="distributions.html#cb15-1"></a>dfnorm &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">vals =</span> x)</span>
<span id="cb15-2"><a href="distributions.html#cb15-2"></a></span>
<span id="cb15-3"><a href="distributions.html#cb15-3"></a>p &lt;-<span class="st"> </span><span class="kw">ggplot</span>(dfnorm, <span class="kw">aes</span>(<span class="dt">x =</span> vals))  <span class="op">+</span><span class="st"> </span></span>
<span id="cb15-4"><a href="distributions.html#cb15-4"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">y =</span> ..density..), <span class="dt">color =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;purple&quot;</span>, <span class="dt">alpha=</span>.<span class="dv">4</span>, <span class="dt">binwidth =</span> <span class="fl">0.5</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb15-5"><a href="distributions.html#cb15-5"></a><span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">alpha =</span> <span class="fl">0.7</span>, <span class="dt">fill =</span> <span class="st">&quot;mistyrose&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb15-6"><a href="distributions.html#cb15-6"></a><span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span></span>
<span id="cb15-7"><a href="distributions.html#cb15-7"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;values&quot;</span>)</span>
<span id="cb15-8"><a href="distributions.html#cb15-8"></a></span>
<span id="cb15-9"><a href="distributions.html#cb15-9"></a>p</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Normal distributions can vary in their means and standard deviations. Below is an image of a selection of four different normal distributions that all vary in their means and standard deviations. The dotted vertical black line in each graph indicates where their respective means lie.</p>
<p><img src="img/norm.png" /></p>
<p>We use special notation to indicate that a distribution is a Normal Distribution. For instance, for the normal distribution that has a mean of 17 and a standard deviation of 7, we would write:</p>
<p><span class="math inline">\(N(\mu=17, \sigma^{2}=49)\)</span></p>
<p>which demonstrates that the distribution is approximately normal with a mean of 17 and variance of 49 (which is the standard deviation, 7, squared).</p>
</div>
<div id="standard-normal-distribution" class="section level3">
<h3><span class="header-section-number">7.0.4</span> Standard Normal Distribution</h3>
<p>Although normal distributions can have various means or standard deviations, there is one case that we reserve and call the standard normal distribution. This is for the situation where the mean of the distribution is 0 and the standard deviation (and the variance) is equal to 1.</p>
<p><span class="math inline">\(N(\mu=0, \sigma^{2}=1)\)</span></p>
<p><img src="img/stdnorm.png" /></p>
<p>How does the standard normal distribution come about? We will discuss more about this distribution in section <a href="distributions.html#normal-distribution">7.0.3</a>, but briefly it is obtained by converting all the values of a normal distribution into z-scores. z-scores are calculated by:</p>
<p><span class="math inline">\(\Large z=\frac{x - {\mu}_x}{\sigma_x}\)</span></p>
<p>This standard normal distribution is very useful in statistics because we can precisely calcualte the proportion of the distribution that is to the left or right under the curve at any point of it. This principle forms the basis of several statistical tests.</p>
</div>
<div id="skewness-and-kurtosis" class="section level3">
<h3><span class="header-section-number">7.0.5</span> Skewness and Kurtosis</h3>
<p>Above we described that a normal distribution has a skewness of 0 and a kurtosis of 3, but then we just skipped along and didn’t really say anything else. It’s important to take a quick step back and think about these two things.</p>
<div id="skewness" class="section level4">
<h4><span class="header-section-number">7.0.5.1</span> Skewness</h4>
<p>We most commonly evaluate skewness for unimodal distributions (those with one peak). The skewness of a distribution can be either negative or positive, or, if it has no skew whatsoever it will be 0.</p>
<p>It is probably easiest to describe skewness by looking at examples. In the picture below, all distributions have a mean of 100 and a standard deviation of 20. However, they differ in their skewness. The one on the left has a skew of +0.68, the one on the right has a skew of -0.68. The one in the middle has a skew of 0 and is the only one that is normally distributed.</p>
<div class="figure">
<img src="img/skew.png" alt="" />
<p class="caption">Skewness</p>
</div>
<p>Distributions that have negative skew are also called left skewed because their longest tail extends to the left of the distribution. Similarly, distributions that have positive skew are called right skewed because their longest tail extends to the right of the distribution.</p>
<p>Another thing to consider about the skew of the distribution is what happens to the mean, median and mode of the distributions.</p>
<p>First, let’s look at the normal distribution we made earlier in this section that had a mean of approximately 100 and a standard deviation of approximately 5. If we get the median, mode and mean of that distribution, we get the following:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="distributions.html#cb16-1"></a><span class="kw">mean</span>(x)</span></code></pre></div>
<pre><code>## [1] 100.0002</code></pre>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="distributions.html#cb18-1"></a><span class="kw">median</span>(x)</span></code></pre></div>
<pre><code>## [1] 100.0025</code></pre>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="distributions.html#cb20-1"></a><span class="kw">estimate_mode</span>(x) <span class="co"># R doesn&#39;t have a built in mode function, so I&#39;m using this as a proxy</span></span></code></pre></div>
<pre><code>## [1] 100.05</code></pre>
<p>We can see here, that all three values are really close to 100. We can look at this in our plot of the distribution. We’ve overlaid a red line for the mean, a blue line for the median and an orange line for the mode. However, they all lie on top of each other at x=100, so it’s hard to distinguish them:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="distributions.html#cb22-1"></a>p <span class="op">+</span><span class="st"> </span></span>
<span id="cb22-2"><a href="distributions.html#cb22-2"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="kw">median</span>(x), <span class="dt">color =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lwd=</span><span class="dv">1</span>)<span class="op">+</span><span class="st"> </span></span>
<span id="cb22-3"><a href="distributions.html#cb22-3"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="kw">mean</span>(x), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">1</span>)<span class="op">+</span><span class="st"> </span></span>
<span id="cb22-4"><a href="distributions.html#cb22-4"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="kw">estimate_mode</span>(x), <span class="dt">color =</span> <span class="st">&quot;darkorange&quot;</span>, <span class="dt">lwd=</span><span class="dv">1</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Now let’s look at some skewed distributions as to what happens to the mode, median and mean in such distributions.</p>
<p>In this dataset, we have 7486 rows of data (observations). Each row is a MLB player. The three numerical columns refer to the career total hits (<code>totalH</code>), career total at bats (<code>totalAB</code>), and career batting average (<code>avg</code>) of each player.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="distributions.html#cb23-1"></a>bats &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data/batting.csv&quot;</span>)</span></code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   playerID = col_character(),
##   totalH = col_double(),
##   totalAB = col_double(),
##   avg = col_double()
## )</code></pre>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="distributions.html#cb25-1"></a><span class="kw">nrow</span>(bats)</span></code></pre></div>
<pre><code>## [1] 7486</code></pre>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="distributions.html#cb27-1"></a><span class="kw">head</span>(bats)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 4
##   playerID  totalH totalAB   avg
##   &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;
## 1 aaronha01   3771   12364 0.305
## 2 aaronto01    216     944 0.229
## 3 abbated01    772    3044 0.254
## 4 abbeybe01     38     225 0.169
## 5 abbeych01    493    1756 0.281
## 6 abbotfr01    107     513 0.209</code></pre>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="distributions.html#cb29-1"></a><span class="co">#histogram</span></span>
<span id="cb29-2"><a href="distributions.html#cb29-2"></a>p1 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(bats, <span class="kw">aes</span>(<span class="dt">x =</span> avg)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb29-3"><a href="distributions.html#cb29-3"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">y =</span> ..density..), </span>
<span id="cb29-4"><a href="distributions.html#cb29-4"></a>                 <span class="dt">color =</span> <span class="st">&quot;black&quot;</span>, </span>
<span id="cb29-5"><a href="distributions.html#cb29-5"></a>                 <span class="dt">fill =</span> <span class="st">&quot;lightseagreen&quot;</span>, </span>
<span id="cb29-6"><a href="distributions.html#cb29-6"></a>                 <span class="dt">alpha =</span> <span class="fl">0.2</span>,</span>
<span id="cb29-7"><a href="distributions.html#cb29-7"></a>                 <span class="dt">binwidth =</span> <span class="fl">.005</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb29-8"><a href="distributions.html#cb29-8"></a><span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">colour =</span> <span class="st">&#39;black&#39;</span>, <span class="dt">lwd=</span><span class="dv">1</span>) <span class="op">+</span></span>
<span id="cb29-9"><a href="distributions.html#cb29-9"></a><span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span></span>
<span id="cb29-10"><a href="distributions.html#cb29-10"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Career Batting Average&quot;</span>)</span>
<span id="cb29-11"><a href="distributions.html#cb29-11"></a></span>
<span id="cb29-12"><a href="distributions.html#cb29-12"></a>p1</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>As you can see, this distribution is very negatively (left) skewed. This means that there are many players who have career batting averages between 0.2 and 0.3. There are relatively few players with career averages over 0.3. There are more averages that are less than 0.2 causing the skew.</p>
<p>We can directly measure the skewness using the <code>skewness()</code> function from the <code>moments</code> package. We can see that it is highly negatively skewed with a value of -1.01:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="distributions.html#cb30-1"></a><span class="kw">library</span>(moments)</span></code></pre></div>
<pre><code>## Warning: package &#39;moments&#39; was built under R version 3.5.2</code></pre>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="distributions.html#cb32-1"></a><span class="kw">skewness</span>(bats<span class="op">$</span>avg) </span></code></pre></div>
<pre><code>## [1] -1.012683</code></pre>
<p>Let’s look at where the median, mean and mode are for this negatively skewed distribution.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="distributions.html#cb34-1"></a><span class="kw">median</span>(bats<span class="op">$</span>avg)</span></code></pre></div>
<pre><code>## [1] 0.2466792</code></pre>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="distributions.html#cb36-1"></a><span class="kw">mean</span>(bats<span class="op">$</span>avg)</span></code></pre></div>
<pre><code>## [1] 0.237972</code></pre>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="distributions.html#cb38-1"></a><span class="kw">estimate_mode</span>(bats<span class="op">$</span>avg)</span></code></pre></div>
<pre><code>## [1] 0.2538827</code></pre>
<p>This time, these descriptive values are not equal. The median and mean are lower than the mode. In fact, the mean is lowest of all.</p>
<p>In negative skewed distributions, the mean and median get pulled towards the skewed tail of the distribution, but the mean gets pulled further.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="distributions.html#cb40-1"></a>p1 <span class="op">+</span><span class="st"> </span></span>
<span id="cb40-2"><a href="distributions.html#cb40-2"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="kw">median</span>(bats<span class="op">$</span>avg), <span class="dt">color =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lwd=</span><span class="dv">1</span>)<span class="op">+</span><span class="st"> </span></span>
<span id="cb40-3"><a href="distributions.html#cb40-3"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="kw">mean</span>(bats<span class="op">$</span>avg), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">1</span>)<span class="op">+</span><span class="st"> </span></span>
<span id="cb40-4"><a href="distributions.html#cb40-4"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="kw">estimate_mode</span>(bats<span class="op">$</span>avg), <span class="dt">color =</span> <span class="st">&quot;darkorange&quot;</span>, <span class="dt">lwd=</span><span class="dv">1</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>Now let’s look at what happens to the mode, median and mean in right skewed distributions. Let’s look at the career at-bats of MLB players.</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="distributions.html#cb41-1"></a><span class="co">#histogram</span></span>
<span id="cb41-2"><a href="distributions.html#cb41-2"></a>p2 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(bats, <span class="kw">aes</span>(<span class="dt">x =</span> totalAB)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb41-3"><a href="distributions.html#cb41-3"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">y =</span> ..density..), </span>
<span id="cb41-4"><a href="distributions.html#cb41-4"></a>                 <span class="dt">color =</span> <span class="st">&quot;black&quot;</span>, </span>
<span id="cb41-5"><a href="distributions.html#cb41-5"></a>                 <span class="dt">fill =</span> <span class="st">&quot;plum&quot;</span>, </span>
<span id="cb41-6"><a href="distributions.html#cb41-6"></a>                 <span class="dt">alpha =</span> <span class="fl">0.2</span>,</span>
<span id="cb41-7"><a href="distributions.html#cb41-7"></a>                 <span class="dt">binwidth =</span> <span class="dv">200</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb41-8"><a href="distributions.html#cb41-8"></a><span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">colour =</span> <span class="st">&#39;black&#39;</span>, <span class="dt">lwd=</span><span class="dv">1</span>) <span class="op">+</span></span>
<span id="cb41-9"><a href="distributions.html#cb41-9"></a><span class="st">  </span><span class="kw">theme_classic</span>()</span>
<span id="cb41-10"><a href="distributions.html#cb41-10"></a></span>
<span id="cb41-11"><a href="distributions.html#cb41-11"></a>p2</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>This distribution is extremely right (positive) skewed. If we measure the skewness we find that the skewness is 1.63.</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="distributions.html#cb42-1"></a><span class="kw">skewness</span>(bats<span class="op">$</span>totalAB)</span></code></pre></div>
<pre><code>## [1] 1.626115</code></pre>
<p>Now, let’s look at the median, mean and mode and plot these on the distribution:</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="distributions.html#cb44-1"></a><span class="kw">median</span>(bats<span class="op">$</span>totalAB)</span></code></pre></div>
<pre><code>## [1] 1037</code></pre>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="distributions.html#cb46-1"></a><span class="kw">mean</span>(bats<span class="op">$</span>totalAB)</span></code></pre></div>
<pre><code>## [1] 1958.68</code></pre>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="distributions.html#cb48-1"></a><span class="kw">estimate_mode</span>(bats<span class="op">$</span>totalAB)</span></code></pre></div>
<pre><code>## [1] 454.0069</code></pre>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="distributions.html#cb50-1"></a>p2 <span class="op">+</span><span class="st"> </span></span>
<span id="cb50-2"><a href="distributions.html#cb50-2"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="kw">median</span>(bats<span class="op">$</span>totalAB), <span class="dt">color =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lwd=</span><span class="dv">1</span>)<span class="op">+</span><span class="st"> </span></span>
<span id="cb50-3"><a href="distributions.html#cb50-3"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="kw">mean</span>(bats<span class="op">$</span>totalAB), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">1</span>)<span class="op">+</span><span class="st"> </span></span>
<span id="cb50-4"><a href="distributions.html#cb50-4"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="kw">estimate_mode</span>(bats<span class="op">$</span>totalAB), <span class="dt">color =</span> <span class="st">&quot;darkorange&quot;</span>, <span class="dt">lwd=</span><span class="dv">1</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>In these severely right skewed distribution, we again see that the median and mean get pulled towards the tail of the distribution, with the mean getting pulled even further than the median.</p>
<p>Let’s have a look at a quick summary figure of where the mean, median and mode lie with respect to each other in skewed distributions. As you can see, the mean always gets pulled the furthest to the tail of distributions.The reason for this is that the mean is much more affected by extreme outliers than the median. The median is simply the boundary which divides the top 50% of the data from the bottom 50% of the data. The mean has to include all values in its calculation, so can be largely affected by extreme values more so than the median.</p>
<div class="figure">
<img src="img/skew1.png" alt="" />
<p class="caption">Skewness</p>
</div>
<p><br></p>
</div>
<div id="kurtosis" class="section level4">
<h4><span class="header-section-number">7.0.5.2</span> Kurtosis</h4>
<p>Another measure of the shape of a data distribution is called kurtosis. Kurtosis relates to how heavy or thin the tails of the distribution are. Often people talk about kurtosis being related to how “peaky” the distribution is, because distributions of different kurtosis values often look to have different peaks - but strictly, kurtosis is about the tails.</p>
<p>We can broadly describe three basic patterns of kurtosis.</p>
<p><em>Mesokurtic</em> - tails are not too thick or too thin - this is the case with the normal distribution.</p>
<p><em>Platykurtic</em> - data is moved more from the center of the distribution to the tails.</p>
<p><em>Leptokurtic</em> - data is taken from the shoulders of the distribution and moved more into the center and slightly to the tails</p>
<p>These are illustrated below:</p>
<p><img src="img/kurtosis.png" /></p>
<p><br></p>
<p>In addition, to using the above funny names to describe the shapes of distributions, we can also actually calculate a kurtosis value. We won’t show the formula here, but effectively the values relate to the patterns as follows.</p>
<p>Mesokurtic distributions have a kurtosis value of approximately 3.</p>
<p>Leptokurtic distributions have a kurtosis value greater than 3.</p>
<p>Platykurtic distributions have a kurtosis value lower than 3.</p>
<p>We can compute this kurtosis value in R using the <code>kurtosis()</code> function from the package <code>moments</code>.</p>
<p>Both our distributions of total at bats and averages have kurtosis values above 3, indicating that they are leptokurtic - i.e. quite peaky and have less data in the shoulders of the distribution.</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="distributions.html#cb51-1"></a><span class="kw">kurtosis</span>(bats<span class="op">$</span>totalAB)   <span class="co"># &gt;3 = &#39;peaky&#39; less in shoulders of tails</span></span></code></pre></div>
<pre><code>## [1] 5.325537</code></pre>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="distributions.html#cb53-1"></a><span class="kw">kurtosis</span>(bats<span class="op">$</span>avg)   <span class="co"># &gt;3 = &#39;peaky&#39; less in shoulders of tails</span></span></code></pre></div>
<pre><code>## [1] 4.18612</code></pre>
<p><br></p>
<p>Another thing of interest is what happens with small sample sizes. Typically small sample sizes are not that normal - that is they are fairly skewed. They are also often fairly platykurtic - they have less data in the center and more in the shoulders and tails of the distribution.</p>
<p>The below shows an example for a sample of 10 scores that come from a normal population of <span class="math inline">\(\mu=100\)</span> and <span class="math inline">\(\sigma=5\)</span>.</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="distributions.html#cb55-1"></a><span class="kw">set.seed</span>(<span class="dv">10</span>)</span>
<span id="cb55-2"><a href="distributions.html#cb55-2"></a>x1 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="dv">10</span>, <span class="dt">mean =</span> <span class="dv">100</span>, <span class="dt">sd =</span> <span class="fl">5.0</span>)</span>
<span id="cb55-3"><a href="distributions.html#cb55-3"></a>x1</span></code></pre></div>
<pre><code>##  [1] 100.09373  99.07874  93.14335  97.00416 101.47273 101.94897  93.95962
##  [8]  98.18162  91.86664  98.71761</code></pre>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="distributions.html#cb57-1"></a><span class="kw">skewness</span>(x1)</span></code></pre></div>
<pre><code>## [1] -0.4021377</code></pre>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="distributions.html#cb59-1"></a><span class="kw">kurtosis</span>(x1)</span></code></pre></div>
<pre><code>## [1] 1.848359</code></pre>
<p>You can see that this small sample is skewed with a skewness of -0.40 and platykurtic with a kurtosis of 1.85.</p>
<p><br><br></p>
</div>
</div>
<div id="z-scores" class="section level2">
<h2><span class="header-section-number">7.1</span> Z-scores</h2>
<p>z-scores are a useful way of comparing different scores in different distributions. As an example, let’s look at the two distributions below. On the left we have the population of all Airedale Terriers that is normally distributed with a mean of 60 lbs with a standard deviation of 6 lbs. On the right we have the population of all Scottish Terriers that is normally distributed with a mean of 20 lbs and a standard deviation of 0.4 lbs.</p>
<div class="figure">
<img src="img/z1.png" alt="" />
<p class="caption">terriers</p>
</div>
<p>If you owned an Airedale Terrier that was 65 lbs and a Scottish Terrier that was 20.5 lbs, would you be able to say which one was relatively larger than their breed average? Both of them are above the mean of their breeds, but by how much? The Airedale Terrier is (65-60) 5 lbs heavier than the mean of the breed, whereas the Scottish Terrier is only (20.5-20) 0.5 lbs heavier than its breed average.</p>
<p>Looking at things in absolute terms however is misleading. It would be better if we could somehow standardize these differences. This is where z-scores come in. z-scores enable us to calcualte how far any datapoint is from the mean of its distribution by saying how many “standard deviations” away from the mean it is.</p>
<p>Let’s look at the Airedale Terrier. Your Airedale is 5 lbs heavier than the mean of 60 lbs. This is a bit less than one standard deviation above the mean, as the standard deviation is 6 lbs. However, your Scottish Terrier is 0.5 lbs heavier than the mean of 20 lbs, which is a bit more than the standard deviation of 0.4 lbs for that breed. We can calculate precisely how many standard deviations away from the mean they are using z-scores. This is the formula:</p>
<p><span class="math inline">\(\Large z=\frac{x - {\mu}_x}{\sigma_x}\)</span></p>
<p>Using this formula, let’s calculate the z-scores for each of our dogs:</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="distributions.html#cb61-1"></a><span class="co">#Airedale</span></span>
<span id="cb61-2"><a href="distributions.html#cb61-2"></a>(<span class="dv">65</span> <span class="op">-</span><span class="st"> </span><span class="dv">60</span>) <span class="op">/</span><span class="st"> </span><span class="dv">6</span></span></code></pre></div>
<pre><code>## [1] 0.8333333</code></pre>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="distributions.html#cb63-1"></a><span class="co">#Scottish</span></span>
<span id="cb63-2"><a href="distributions.html#cb63-2"></a>(<span class="fl">20.5</span> <span class="op">-</span><span class="st"> </span><span class="dv">20</span>) <span class="op">/</span><span class="st"> </span><span class="fl">0.4</span></span></code></pre></div>
<pre><code>## [1] 1.25</code></pre>
<p>The z-score for our 65 lb Airedale is <code>z=0.83</code>. The z-score for our 20.5 lb Scottish is <code>z=1.25</code>. This shows us that our Scottish Terrier is actual more standard deviations away from its breed mean than is our Airedale Terrier dog.</p>
<p>We could also plot each of these z-scores on top of the standard normal distribution. Remember, this is the specific case of the normal distribution where the mean of the distribution is 0 and the standard deviation is 1.</p>
<p>Shown below, we’ve plotted on the top row the breed population histograms with red vertical lines the weights of each of these dogs on their respective population histogram. On the bottom row we have these values converted to their z-scores and still shown with a red line. Each is overlaid on top of a standard normal distribution.</p>
<div class="figure">
<img src="img/z2.png" alt="" />
<p class="caption">z-scores</p>
</div>
<p>z-scores can be very useful ways of standardizing observed values into ways that we can directly compare across different distributions. If we calculate a negative z-score then it’s clear that our observed value is below the population mean, and if we calculate a positive z-score then our value is greater than the population mean. The size of the z-score relates to how many population standard deviations from the mean each value is overall.</p>
<div id="z-scores-in-samples." class="section level3">
<h3><span class="header-section-number">7.1.1</span> z-scores in samples.</h3>
<p>Often we may not know the population mean or standard deviation. In such cases if all we have is a sample mean and a sample standard deviation, we can still calcualte z-scores for such samples. We effectively use the same formula to calculate the z-scores, just subsituting in the sample mean and standard deviation.</p>
<p><span class="math inline">\(\Large z=\frac{x - {\overline{x}}}{s_{x}}\)</span></p>
<p>For instance, let’s look at the following sample of ages for players on a village cricket team:</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="distributions.html#cb65-1"></a>ages &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">23</span>, <span class="dv">19</span>, <span class="dv">21</span>, <span class="dv">33</span>, <span class="dv">51</span>, <span class="dv">40</span>, <span class="dv">16</span>, <span class="dv">15</span>, <span class="dv">61</span>, <span class="dv">55</span>, <span class="dv">30</span>, <span class="dv">28</span>)</span>
<span id="cb65-2"><a href="distributions.html#cb65-2"></a></span>
<span id="cb65-3"><a href="distributions.html#cb65-3"></a><span class="kw">mean</span>(ages)</span></code></pre></div>
<pre><code>## [1] 32.66667</code></pre>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="distributions.html#cb67-1"></a><span class="kw">sd</span>(ages)</span></code></pre></div>
<pre><code>## [1] 15.74417</code></pre>
<p>These data clearly don’t look normally distributed, but we still are able to calculate a mean and standard deviation. We can also still calculate the z-scores for each age:</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="distributions.html#cb69-1"></a>z &lt;-<span class="st"> </span>(ages <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(ages)) <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(ages)</span>
<span id="cb69-2"><a href="distributions.html#cb69-2"></a></span>
<span id="cb69-3"><a href="distributions.html#cb69-3"></a>z</span></code></pre></div>
<pre><code>##  [1] -0.61398401 -0.86804636 -0.74101519  0.02117186  1.16445243  0.46578097
##  [7] -1.05859312 -1.12210871  1.79960831  1.41851478 -0.16937490 -0.29640607</code></pre>
<p>You’ll notice that those individuals that have negative z-scores are younger than the mean age of 32.67. Those individuals with positive z-scores are older than the mean age of 32.67. The largest z-score in terms of magnitude (either in the positive or negative direction) is 1.8. This person was 61 and was 1.8 standard deviations older than the average age.</p>
<p>Although it’s possible to calculate z-scores for any sample, if the sample data come from a normally distributed population then we can use this z-score principle to perform inferential statistics (see xxx.xxx)</p>
</div>
<div id="using-z-scores-to-determine-probabilities" class="section level3">
<h3><span class="header-section-number">7.1.2</span> Using z-scores to determine probabilities</h3>
<p>One of the great things about the normal distribution, is that we can calculate quite straightforwardly what proportion of the distribution lies under the curve for any distance away from the mean measured in standard deviation.</p>
<p>With computers, this is a very trivial task to perform, as we’ll see shortly. Prior to the computer age, these computations weren’t as easy, so we’d often use something called the <strong>empirical rule</strong>. This is basically a framework that tell us what proportion of the distribution lies under the curve at 1<span class="math inline">\(\sigma\)</span>, 2<span class="math inline">\(\sigma\)</span>, 3<span class="math inline">\(\sigma\)</span>, etc. from the mean.</p>
<p>Let’s look at the distribution below, which is normally distributed with a mean (<span class="math inline">\(\mu\)</span>) of 14 and a standard deviation (<span class="math inline">\(\sigma\)</span>) of 4.</p>
<p>The first thing to note is that a normal distribution is perfectly symmetrical, with equal area under the curve on either side of the mean. Therefore, in our example, 50% of the distribution lies below the mean of 14, and 50% of datapoints lie above the mean.</p>
<p>The area colored in green in the distribution represents the area of the distribution that lies <span class="math inline">\(\mu \pm1\sigma\)</span>. The area colored in pinky-purple lie between <span class="math inline">\(\mu+1\sigma\)</span> and <span class="math inline">\(\mu+2\sigma\)</span> or between <span class="math inline">\(\mu-1\sigma\)</span> and <span class="math inline">\(\mu-2\sigma\)</span>. The area colored in yellow lie between <span class="math inline">\(\mu+2\sigma\)</span> and <span class="math inline">\(\mu+3\sigma\)</span> or between <span class="math inline">\(\mu-2\sigma\)</span> and <span class="math inline">\(\mu-3\sigma\)</span>. The blue areas represent the proportion of the distribution that lies beyond <span class="math inline">\(\mu \pm4\sigma\)</span>.</p>
<p><img src="img/empirical.png" style="width:90.0%" /></p>
<p>Rather than look at the proportion that lies between two boundaries, often instead we describe the proportion of the distribution that lies to the left of a certain value. The table below shows what proportion of the distribution lie to the left of each value. For instance, in the above distribution <span class="math inline">\(\mu+2\sigma=22\)</span>. According to the table below, we have 97.72% of the data/distribution that are to the left of <span class="math inline">\(x=22\)</span>.</p>
<p><img src="img/ztable.png" style="width:50.0%" /></p>
<p>The above table and histogram are obviously useful guides for knowing what proportion of the data exist at certain breakpoints. But, what if you had a value of <span class="math inline">\(x=17.5\)</span> in the above distribution? What proportion of the data are below this value?</p>
<p>Well we can actually work this out if we convert our raw scores to z-scores. Once we have a z-score, we can calculate the area to the left of any point on the standard normal curve. Our value of <span class="math inline">\(x=17.5\)</span> has a z-score of 0.875, so it is 0.875 standard deviations above the mean.</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="distributions.html#cb71-1"></a>(<span class="fl">17.5</span> <span class="op">-</span><span class="st"> </span><span class="dv">14</span>) <span class="op">/</span><span class="dv">4</span></span></code></pre></div>
<pre><code>## [1] 0.875</code></pre>
<p>Let’s look at that on the standard normal curve, with the value <span class="math inline">\(z = 0.875\)</span> represented by the red solid line. We can obtain the area in the distribution to the left of this value that is shaded in light red in R, using the function <code>pnorm()</code>.</p>
<p><img src="img/z3.png" /></p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="distributions.html#cb73-1"></a><span class="kw">pnorm</span>(<span class="fl">0.875</span>)</span></code></pre></div>
<pre><code>## [1] 0.809213</code></pre>
<p>This shows us that 80.92% of the distribution lie to the left of <span class="math inline">\(z=0.875\)</span>. To get what proportion of the distribution lie to the right of this value, we just subtract it from 1.</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="distributions.html#cb75-1"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="fl">0.875</span>)</span></code></pre></div>
<pre><code>## [1] 0.190787</code></pre>
<p>Let’s look at the proportions under the curve to the left of plus or minus 0, 1, 2, or 3 standard deviations from the mean.</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="distributions.html#cb77-1"></a>zvals &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="dv">3</span>,<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>)</span>
<span id="cb77-2"><a href="distributions.html#cb77-2"></a><span class="kw">pnorm</span>(zvals)</span></code></pre></div>
<pre><code>## [1] 0.001349898 0.022750132 0.158655254 0.500000000 0.841344746 0.977249868
## [7] 0.998650102</code></pre>
<p>Hopefully you can see that these values mirror those in the table provided above.</p>
<p><br></p>
<div id="z-score-and-probability-problems." class="section level4">
<h4><span class="header-section-number">7.1.2.1</span> z-score and probability problems.</h4>
<p>Let’s take this a little further with some small examples.</p>
<p><strong>Example 1</strong></p>
<p>Let’s assume that the weights of pineapples are normally distributed with a mean of 1003.5g and a standard deviation of 35g. You bought a random pineapple and it turned out to only be 940g. What proportion of pineapples are less than 940g? How unlucky did you get to buy such a small pineapple?</p>
<p>First, let’s take a look at the population distribution of pineapples with <span class="math inline">\(\mu=1003.5\)</span> and <span class="math inline">\(\sigma=35\)</span>. Our pineapple is 940g and is shown with the solid red line below. As our distribution is normal, if we convert this to a z-score we can compare it to where z is in the standard normal distribution on the right.</p>
<p><img src="img/z4.png" /></p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="distributions.html#cb79-1"></a>(<span class="dv">940</span> <span class="op">-</span><span class="st"> </span><span class="fl">1003.5</span>) <span class="op">/</span><span class="st"> </span><span class="dv">35</span></span></code></pre></div>
<pre><code>## [1] -1.814286</code></pre>
<p>So we calculated that <span class="math inline">\(z = -1.81\)</span>, and we visualize that on our standard normal distribution. We’re interested in what proportion of pineapples from the distribution are 940g or less. That is the light red shaded area. To calculate that we can just use <code>pnorm()</code> in R:</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="distributions.html#cb81-1"></a><span class="kw">pnorm</span>(<span class="op">-</span><span class="fl">1.81</span>)</span></code></pre></div>
<pre><code>## [1] 0.03514789</code></pre>
<p>From this we can see that only 3.5% of pineapples are less than 940g. We got super unlucky to get such a tiny pineapple.</p>
<p><strong>Example 2</strong></p>
<p>What is the probability of getting a pineapple of greater than 1050g ?</p>
<p>To answer this we first get the z-score for a pineapple of 1050g, and find that <span class="math inline">\(z = 1.33\)</span>.</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="distributions.html#cb83-1"></a>(<span class="dv">1050</span> <span class="op">-</span><span class="st"> </span><span class="fl">1003.5</span>) <span class="op">/</span><span class="st"> </span><span class="dv">35</span></span></code></pre></div>
<pre><code>## [1] 1.328571</code></pre>
<p>Next we recognize that if we’re interested in what proportion of pineapples weigh more than 1050g, we need to know what proportion of the standard normal curve is greater than <span class="math inline">\(z = 1.33\)</span> (the shaded light red area below).</p>
<p><img src="img/z5.png" /></p>
<p>We can calculate that by using <code>pnorm()</code> to figure out what proportion is to the left of <span class="math inline">\(z = 1.33\)</span>, and then subtract that from 1 to get what proportion is to the right.</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="distributions.html#cb85-1"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="fl">1.33</span>)   <span class="co">#0.003  (so 9.18% chance)</span></span></code></pre></div>
<pre><code>## [1] 0.09175914</code></pre>
<p><strong>Example 3</strong></p>
<p>What is the probability of getting a pineapple between 950g and 1045g ?</p>
<p>For this question, we’re interested in the shaded light red area between <span class="math inline">\(z = x\)</span> and <span class="math inline">\(z = z\)</span> on the standard normal curve. Why these z-values? Because these are the z scores you get if you convert a 950g and a 1045g pineapple to z scores.</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="distributions.html#cb87-1"></a>z1 &lt;-<span class="st"> </span>(<span class="dv">950</span> <span class="op">-</span><span class="st"> </span><span class="fl">1003.5</span>)  <span class="op">/</span><span class="st"> </span><span class="dv">35</span></span>
<span id="cb87-2"><a href="distributions.html#cb87-2"></a>z2 &lt;-<span class="st"> </span>(<span class="dv">1045</span> <span class="op">-</span><span class="st"> </span><span class="fl">1003.5</span>)  <span class="op">/</span><span class="st"> </span><span class="dv">35</span></span>
<span id="cb87-3"><a href="distributions.html#cb87-3"></a></span>
<span id="cb87-4"><a href="distributions.html#cb87-4"></a>z1 <span class="co">#-1.53</span></span></code></pre></div>
<pre><code>## [1] -1.528571</code></pre>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="distributions.html#cb89-1"></a>z2 <span class="co">#1.19</span></span></code></pre></div>
<pre><code>## [1] 1.185714</code></pre>
<p><img src="img/z6.png" /></p>
<p>In R we can calculate the proportion to the left of each of these z-scores using <code>pnorm()</code>. What we need is the shaded area, which we can get if we subtract the area to the left of <span class="math inline">\(z = -1.53\)</span> from the area to the left of <span class="math inline">\(z = 1.19\)</span>. We do it like this:</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="distributions.html#cb91-1"></a><span class="co">## get proportion of curve to left of each z-score</span></span>
<span id="cb91-2"><a href="distributions.html#cb91-2"></a></span>
<span id="cb91-3"><a href="distributions.html#cb91-3"></a><span class="kw">pnorm</span>(z1) <span class="co"># 0.06</span></span></code></pre></div>
<pre><code>## [1] 0.06318536</code></pre>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="distributions.html#cb93-1"></a><span class="kw">pnorm</span>(z2) <span class="co"># 0.88</span></span></code></pre></div>
<pre><code>## [1] 0.8821324</code></pre>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="distributions.html#cb95-1"></a><span class="co"># so the area between them is:</span></span>
<span id="cb95-2"><a href="distributions.html#cb95-2"></a></span>
<span id="cb95-3"><a href="distributions.html#cb95-3"></a><span class="kw">pnorm</span>(z2) <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(z1)  <span class="co">#0.82</span></span></code></pre></div>
<pre><code>## [1] 0.8189471</code></pre>
<p>So, 82% of the distribution lie between 950g and 1040g.</p>
<p><br><br></p>
</div>
</div>
</div>
<div id="what-is-a-sampling-distribution" class="section level2">
<h2><span class="header-section-number">7.2</span> What is a Sampling Distribution ?</h2>
<p>Another type of distribution that we will discuss a lot! is the sampling distribution. There are different types of sampling distributions, so for now we’ll focus on the <strong>sampling distribution of the sample means</strong>. The best way to illustrate a sampling distribution, is to show it by example.</p>
<p>Say we have a population of 1 million adult Archerfish. The population mean of their bodylength is <span class="math inline">\(\mu = 100.0mm\)</span>, and the population standard deviation is <span class="math inline">\(\sigma = 15.0mm\)</span>.</p>
<p>Let’s create this population:</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb97-1"><a href="distributions.html#cb97-1"></a><span class="kw">set.seed</span>(<span class="dv">3</span>)</span>
<span id="cb97-2"><a href="distributions.html#cb97-2"></a></span>
<span id="cb97-3"><a href="distributions.html#cb97-3"></a>archerfish &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="dv">1000000</span>, <span class="dt">mean =</span> <span class="dv">100</span>, <span class="dt">sd =</span> <span class="dv">15</span>)</span>
<span id="cb97-4"><a href="distributions.html#cb97-4"></a></span>
<span id="cb97-5"><a href="distributions.html#cb97-5"></a><span class="kw">mean</span>(archerfish)</span></code></pre></div>
<pre><code>## [1] 100.0061</code></pre>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="distributions.html#cb99-1"></a><span class="kw">sd</span>(archerfish)</span></code></pre></div>
<pre><code>## [1] 15.02418</code></pre>
<p>Let’s also plot what this normally distrubted population looks like by making a histogram:</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="distributions.html#cb101-1"></a><span class="co"># histogram of the population:</span></span>
<span id="cb101-2"><a href="distributions.html#cb101-2"></a></span>
<span id="cb101-3"><a href="distributions.html#cb101-3"></a><span class="kw">ggplot</span>(<span class="kw">data.frame</span>(archerfish), <span class="kw">aes</span>(<span class="dt">x =</span> archerfish)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb101-4"><a href="distributions.html#cb101-4"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&#39;black&#39;</span>, <span class="dt">fill=</span><span class="st">&#39;#f584ed&#39;</span>, <span class="dt">alpha=</span>.<span class="dv">5</span>, <span class="dt">binwidth =</span><span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb101-5"><a href="distributions.html#cb101-5"></a><span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span></span>
<span id="cb101-6"><a href="distributions.html#cb101-6"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Body Length mm&quot;</span>) <span class="op">+</span></span>
<span id="cb101-7"><a href="distributions.html#cb101-7"></a><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Frequency&quot;</span>) <span class="op">+</span></span>
<span id="cb101-8"><a href="distributions.html#cb101-8"></a><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Body Sizes of 1 million Archerfish&quot;</span>) <span class="op">+</span></span>
<span id="cb101-9"><a href="distributions.html#cb101-9"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="fl">100.0</span>, <span class="dt">lwd=</span><span class="dv">1</span>, <span class="dt">color=</span><span class="st">&#39;black&#39;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<p>OK, let’s say that you didn’t have the time to go out and catch 1 million archerfish and measure the body length of every single fish. What should you do? One thing you might decide is to just go and take a random sample of 10 archererfish (you could have picked another sample size - let’s just stick with 10 for now). Once you have your sample of 10 archerfish, you could then measure them and you will be able to calculate the sample mean of that sample.</p>
<p>We’ll use <code>sample()</code> to randomly select 10 archerfish.</p>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="distributions.html#cb102-1"></a><span class="kw">set.seed</span>(<span class="dv">1</span>) <span class="co"># so we all get the same sample.</span></span>
<span id="cb102-2"><a href="distributions.html#cb102-2"></a>samp1 &lt;-<span class="st"> </span><span class="kw">sample</span>(archerfish, <span class="dv">10</span>, <span class="dt">replace =</span> T)  </span>
<span id="cb102-3"><a href="distributions.html#cb102-3"></a></span>
<span id="cb102-4"><a href="distributions.html#cb102-4"></a>samp1</span></code></pre></div>
<pre><code>##  [1]  83.93889 103.18896  77.19206 104.34995  98.54528 111.00236  85.95220
##  [8]  94.26505  99.79486  97.50949</code></pre>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="distributions.html#cb104-1"></a><span class="kw">mean</span>(samp1)</span></code></pre></div>
<pre><code>## [1] 95.57391</code></pre>
<p>Our sample mean is <span class="math inline">\(\overline{x}=95.6\)</span> - that’s fairly close to the actual population mean of 100.0mm. Let’s grab another three samples of 10 archerfish and see what the sample means are of those sample:</p>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="distributions.html#cb106-1"></a><span class="kw">mean</span>(<span class="kw">sample</span>(archerfish, <span class="dv">10</span>, <span class="dt">replace =</span> T))  <span class="co"># mean of our 2nd sample</span></span></code></pre></div>
<pre><code>## [1] 98.35256</code></pre>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="distributions.html#cb108-1"></a><span class="kw">mean</span>(<span class="kw">sample</span>(archerfish, <span class="dv">10</span>, <span class="dt">replace =</span> T))  <span class="co"># mean of our 3rd sample</span></span></code></pre></div>
<pre><code>## [1] 100.4263</code></pre>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="distributions.html#cb110-1"></a><span class="kw">mean</span>(<span class="kw">sample</span>(archerfish, <span class="dv">10</span>, <span class="dt">replace =</span> T))  <span class="co"># mean of our 4th sample</span></span></code></pre></div>
<pre><code>## [1] 99.98449</code></pre>
<p>These next three samples are closer to 100.0, with one just above and two just below 100.</p>
<p>What would happen if we collected thousands and thousands of samples of size 10? Let’s do it - you don’t need to follow the exact code here of how we’re doing this, but essentially we’re grabbing 20,000 samples of size 10. From each of these we’re getting the sample mean. That means we’ll end up with 20,000 sample means. We’re storing those results in the object called <code>res</code>.</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="distributions.html#cb112-1"></a><span class="co">### What if we were to collect 20,000 samples and for each one get the mean</span></span>
<span id="cb112-2"><a href="distributions.html#cb112-2"></a></span>
<span id="cb112-3"><a href="distributions.html#cb112-3"></a>results&lt;-<span class="kw">vector</span>(<span class="st">&#39;list&#39;</span>,<span class="dv">20000</span>)</span>
<span id="cb112-4"><a href="distributions.html#cb112-4"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">20000</span>){</span>
<span id="cb112-5"><a href="distributions.html#cb112-5"></a>results[[i]]  &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">sample</span>(archerfish, <span class="dv">10</span>, <span class="dt">replace =</span> T))  </span>
<span id="cb112-6"><a href="distributions.html#cb112-6"></a>}</span>
<span id="cb112-7"><a href="distributions.html#cb112-7"></a></span>
<span id="cb112-8"><a href="distributions.html#cb112-8"></a>res &lt;-<span class="st"> </span><span class="kw">unlist</span>(results)</span></code></pre></div>
<p>Now we have our 20,000 sample means we could make a histogram of these sample means.</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="distributions.html#cb113-1"></a>psd &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">data.frame</span>(res), <span class="kw">aes</span>(<span class="dt">x =</span> res)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb113-2"><a href="distributions.html#cb113-2"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&#39;black&#39;</span>, <span class="dt">fill=</span><span class="st">&#39;#4adbe0&#39;</span>, <span class="dt">alpha=</span>.<span class="dv">5</span>, <span class="dt">binwidth =</span> <span class="dv">1</span>) <span class="op">+</span></span>
<span id="cb113-3"><a href="distributions.html#cb113-3"></a><span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span></span>
<span id="cb113-4"><a href="distributions.html#cb113-4"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Mean Body Length of each sample - mm&quot;</span>) <span class="op">+</span></span>
<span id="cb113-5"><a href="distributions.html#cb113-5"></a><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Frequency&quot;</span>) <span class="op">+</span></span>
<span id="cb113-6"><a href="distributions.html#cb113-6"></a><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Sampling Distribution of Sample Means for n=10&quot;</span>) <span class="op">+</span></span>
<span id="cb113-7"><a href="distributions.html#cb113-7"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="kw">mean</span>(res), <span class="dt">lwd=</span><span class="dv">1</span>)</span>
<span id="cb113-8"><a href="distributions.html#cb113-8"></a></span>
<span id="cb113-9"><a href="distributions.html#cb113-9"></a>psd</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-35-1.png" width="672" /></p>
<p>This distribution that we’ve just plotted is the <strong>sampling distribution of sample means for samples of size n=10</strong>. We picked 20,000 as the number of samples of size 10 to collect as it’s reasonably large enough to get enough sample means that we can see the shape of the distribution. We could have picked 100,000 samples to collect, or 1,000,000… in fact the more the better, but 20,000 is enough to get the point across.</p>
<p>Out of all of these sample means that we “collected”, what is the average across all of the 20,000 samples? - and what’s more, what is the standard deviation of that distribution?</p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="distributions.html#cb114-1"></a><span class="kw">mean</span>(res)</span></code></pre></div>
<pre><code>## [1] 99.99576</code></pre>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="distributions.html#cb116-1"></a><span class="kw">sd</span>(res) <span class="co">#standard deviation of the sampling distribution, aka standard error</span></span></code></pre></div>
<pre><code>## [1] 4.763135</code></pre>
<p>Let’s first focus on the mean. Our mean of sample means was 99.996, which is very approximately the same as the mean of 1,000,000 archerfish in the population! It turns out that the mean of the sampling distribution is approximately equal to the population mean. By the way, the notation that we use to depcit the mean of the sampling distribution of sample means is <span class="math inline">\(\mu_{\overline{x}}\)</span>. So <span class="math inline">\(\mu_{\overline{x}} = 100.0\)</span>.</p>
<p>What is the standard deviation of this distribution (the sampling distribution of the sample means)? We just calculated it in R to be 4.77. The notation we use for this is <span class="math inline">\(\sigma_{\overline{x}} = 4.77\)</span>. It’s called the standard deviation of the sampling distribution of sample means, but for short it gets called the <strong>standard error</strong>.</p>
<p>Of course, we never in reality actually collect thousands and thousands of samples - that defeats the point of sampling. If we had time to collect thousands and thousands of samples, we may as well just measure every archerfish in the population. Usually, we just collect one sample. In later sections, we’ll discuss how you can estimate what <span class="math inline">\(\mu_{\overline{x}}\)</span> and <span class="math inline">\(\sigma_{\overline{x}}\)</span> are when you have only collected one sample.</p>
<p>However, given we already know the population standard deviation of the 1 million archerfish is <span class="math inline">\(\sigma=15\)</span>, we can calculate the standard deviation of the sampling distribution of sample means for any sample size. It is calculated using the formula:</p>
<p><span class="math inline">\(\Large \sigma_{\overline{x}} = \frac{\sigma}{\sqrt{n}}\)</span></p>
<p>So in our case it should be equal to:</p>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="distributions.html#cb118-1"></a><span class="dv">15</span><span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">10</span>) <span class="co"># 4.74</span></span></code></pre></div>
<pre><code>## [1] 4.743416</code></pre>
<p>As you can see this is very close to the value that we got in our simulated sampling distribution above.</p>
<p><br></p>
<div id="sample-size-and-the-sampling-distribution" class="section level3">
<h3><span class="header-section-number">7.2.1</span> Sample Size and the Sampling Distribution</h3>
<p>In the previous section we looked at what would happen if we took samples of size 10 from our archerfish population and looked at the sample means of each sample. We found that when we made a histogram out of these sample means, that the mean of the sample means <span class="math inline">\(\mu_{\overline{x}}\)</span> was approximately equal to the population mean of 100. The standard deviation of the sampling distribution of sample means, or standard error, <span class="math inline">\(\sigma_{\overline{x}}\)</span> was approximately equal to 4.74.</p>
<p>What happens if we were to take a different sized sample each time - say size 50? What would be the mean and standard deviation of this distribution of sample means? Let’s find out. We’ll again take 20000 samples of size 50 at random from our population of 1 million archerfish. For each sample we’ll record the sample mean length of the 50 fish. We’ll end up saving these 20,000 sample means in an R object called <code>res1</code>. Again, don’t worry about how the code is doing it here, just as long as you follow what we’re doing.</p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="distributions.html#cb120-1"></a><span class="co"># ok, get 20,000 samples of size 50</span></span>
<span id="cb120-2"><a href="distributions.html#cb120-2"></a>results1&lt;-<span class="kw">vector</span>(<span class="st">&#39;list&#39;</span>,<span class="dv">20000</span>)</span>
<span id="cb120-3"><a href="distributions.html#cb120-3"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">20000</span>){</span>
<span id="cb120-4"><a href="distributions.html#cb120-4"></a>  results1[[i]]  &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">sample</span>(archerfish, <span class="dv">50</span>, <span class="dt">replace =</span> T))</span>
<span id="cb120-5"><a href="distributions.html#cb120-5"></a>}</span>
<span id="cb120-6"><a href="distributions.html#cb120-6"></a></span>
<span id="cb120-7"><a href="distributions.html#cb120-7"></a>res1 &lt;-<span class="st"> </span><span class="kw">unlist</span>(results1)</span></code></pre></div>
<p>Now we have our 20,000 samples, let’s plot the histogram</p>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="distributions.html#cb121-1"></a>psd2 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">data.frame</span>(res1), <span class="kw">aes</span>(<span class="dt">x =</span> res1)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb121-2"><a href="distributions.html#cb121-2"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&#39;black&#39;</span>, <span class="dt">fill=</span><span class="st">&#39;#4adbe0&#39;</span>, <span class="dt">alpha=</span>.<span class="dv">5</span>, <span class="dt">binwidth =</span> <span class="fl">.5</span>) <span class="op">+</span></span>
<span id="cb121-3"><a href="distributions.html#cb121-3"></a><span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span></span>
<span id="cb121-4"><a href="distributions.html#cb121-4"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Mean Body Length of each sample - mm&quot;</span>) <span class="op">+</span></span>
<span id="cb121-5"><a href="distributions.html#cb121-5"></a><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Frequency&quot;</span>) <span class="op">+</span></span>
<span id="cb121-6"><a href="distributions.html#cb121-6"></a><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Sampling Distribution of Sample Means for n=50&quot;</span>)<span class="op">+</span></span>
<span id="cb121-7"><a href="distributions.html#cb121-7"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="kw">mean</span>(res1),<span class="dt">lwd=</span><span class="dv">1</span>)</span>
<span id="cb121-8"><a href="distributions.html#cb121-8"></a></span>
<span id="cb121-9"><a href="distributions.html#cb121-9"></a>psd2</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
<p>If we look at the mean and standard deviation of this sampling distribution, we get the following values:</p>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="distributions.html#cb122-1"></a><span class="kw">mean</span>(res1)  <span class="co"># still same as population mean</span></span></code></pre></div>
<pre><code>## [1] 100.0088</code></pre>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="distributions.html#cb124-1"></a><span class="kw">sd</span>(res1)    <span class="co"># smaller with larger sample size</span></span></code></pre></div>
<pre><code>## [1] 2.130018</code></pre>
<p>The mean of the sampling distribution of sample means <span class="math inline">\(\mu_{\overline{x}}\)</span> is still a very good estimate of the population mean.</p>
<p>The biggest difference is in the standard deviation of the sampling distribution, <span class="math inline">\(\sigma_{\overline{x}}\)</span> (the standard error), which is much lower than when we had samples of size 10. The reason for this is that the variability in our sample means is much more reduced when we have samples of size 50. On average, our sample means are much closer individual estimates to the population mean. This is what drastically reduces the standard deviation of this sampling distribution.</p>
<p>We could have calculated the standard error directly using the formula provided earlier, because we already know the population standard deviation. When we use that formala we get 2.12, almost the same standard deviation as we got with our simulated sampling distribution:</p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="distributions.html#cb126-1"></a><span class="dv">15</span> <span class="op">/</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="dv">50</span>)</span></code></pre></div>
<pre><code>## [1] 2.12132</code></pre>
<p>Let’s directly compare the two sampling distributions for the two different sample sizes. We adjusted the x-axis so it is the same for both figures, so you can see the change in the standard deviation between the two sample sizes:</p>
<p><img src="_main_files/figure-html/unnamed-chunk-42-1.png" width="672" /></p>
<p><br><br></p>
</div>
</div>
<div id="central-limit-theorem" class="section level2">
<h2><span class="header-section-number">7.3</span> Central Limit Theorem</h2>
<p>In the previous section we discovered that if you take many, many samples from a normally distributed population and calculated the sample mean of each sample, that you would get a sampling distribution of sample means. We also saw that that sampling distribution was normally distributed with a mean <span class="math inline">\(\mu_{\overline{x}}\)</span> that was approximately equal to the population mean, and a standard deviation <span class="math inline">\(\sigma_{\overline{x}}\)</span> that was equal to the population standard deviation divided by the square root of n <span class="math inline">\(\Large \sigma_{\overline{x}} = \frac{\sigma}{\sqrt{n}}\)</span>.</p>
<p>Is it just coincidence that both the population distribution and the sampling distribution was approximately normally distributed? What we will learn in this chapter is that it does not matter at all what the population distribution is - if we take thousands of samples from <strong>any</strong> shaped distribution and calculate the sample mean of each sample, when we create the histogram of those sample means we will find that they are approximately normally distributed. This is what we refer to as the <strong>central limit theorem</strong>. Further, the larger the sample size that we take, the closer to a normal distribution the sampling distribution becomes.</p>
<p>Let’s look at this by taking samples from various different population distributions.</p>
<p><br></p>
<p><strong>Uniform Distribution</strong></p>
<p>First we’ll look at a uniform distribution of 1 million numbers between 0 and 75. You might like to think of this as the distance of trees from the center of a forest in km. Let’s graph the distribution and calculate the mean and standard deviation.</p>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="distributions.html#cb128-1"></a><span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb128-2"><a href="distributions.html#cb128-2"></a></span>
<span id="cb128-3"><a href="distributions.html#cb128-3"></a><span class="co">#get data from uniform distribution</span></span>
<span id="cb128-4"><a href="distributions.html#cb128-4"></a>x1 &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">1000000</span>, <span class="dt">min =</span> <span class="dv">0</span>, <span class="dt">max =</span> <span class="dv">75</span>)</span>
<span id="cb128-5"><a href="distributions.html#cb128-5"></a></span>
<span id="cb128-6"><a href="distributions.html#cb128-6"></a><span class="co"># histogram</span></span>
<span id="cb128-7"><a href="distributions.html#cb128-7"></a><span class="kw">ggplot</span>(<span class="kw">data.frame</span>(x1), <span class="kw">aes</span>(<span class="dt">x =</span> x1)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb128-8"><a href="distributions.html#cb128-8"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&#39;black&#39;</span>, </span>
<span id="cb128-9"><a href="distributions.html#cb128-9"></a>                 <span class="dt">fill =</span> <span class="st">&quot;#894ae0&quot;</span>, </span>
<span id="cb128-10"><a href="distributions.html#cb128-10"></a>                 <span class="dt">alpha=</span>.<span class="dv">3</span>, </span>
<span id="cb128-11"><a href="distributions.html#cb128-11"></a>                 <span class="dt">binwidth =</span> <span class="dv">5</span>,</span>
<span id="cb128-12"><a href="distributions.html#cb128-12"></a>                 <span class="dt">boundary =</span> <span class="dv">0</span>) <span class="op">+</span></span>
<span id="cb128-13"><a href="distributions.html#cb128-13"></a><span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span></span>
<span id="cb128-14"><a href="distributions.html#cb128-14"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Distance from Center of Forest km&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-43-1.png" width="672" /></p>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="distributions.html#cb129-1"></a><span class="co">### Population Mean &amp; SD</span></span>
<span id="cb129-2"><a href="distributions.html#cb129-2"></a><span class="kw">mean</span>(x1)  <span class="co">#37.5</span></span></code></pre></div>
<pre><code>## [1] 37.49417</code></pre>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="distributions.html#cb131-1"></a><span class="kw">sd</span>(x1) <span class="co">#21.6</span></span></code></pre></div>
<pre><code>## [1] 21.6472</code></pre>
<p>We can see that the mean of this population is 37.5, and the population standard deviation is 21.6.</p>
<p>Let’s take samples of size 30 at random from this population of 1 million. For each sample, we’ll calculate the sample mean. We’ll take 10,000 samples (again - we could have picked any really large number here, but 10,000 seems reasonable enough to prove our point). After we get our 10,000 sample means from samples of size 30, we’ll plot the histogram of those sample means.</p>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="distributions.html#cb133-1"></a><span class="co">## Let&#39;s get 10,000 samples of size 30</span></span>
<span id="cb133-2"><a href="distributions.html#cb133-2"></a></span>
<span id="cb133-3"><a href="distributions.html#cb133-3"></a>results&lt;-<span class="kw">vector</span>(<span class="st">&#39;list&#39;</span>,<span class="dv">10000</span>)</span>
<span id="cb133-4"><a href="distributions.html#cb133-4"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">10000</span>){</span>
<span id="cb133-5"><a href="distributions.html#cb133-5"></a>  results[[i]]  &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">sample</span>(x1, <span class="dv">30</span>, <span class="dt">replace =</span> T))  </span>
<span id="cb133-6"><a href="distributions.html#cb133-6"></a>}</span>
<span id="cb133-7"><a href="distributions.html#cb133-7"></a></span>
<span id="cb133-8"><a href="distributions.html#cb133-8"></a>res &lt;-<span class="st"> </span><span class="kw">unlist</span>(results)</span>
<span id="cb133-9"><a href="distributions.html#cb133-9"></a></span>
<span id="cb133-10"><a href="distributions.html#cb133-10"></a></span>
<span id="cb133-11"><a href="distributions.html#cb133-11"></a><span class="co"># This is the sampling distribution.</span></span>
<span id="cb133-12"><a href="distributions.html#cb133-12"></a><span class="kw">ggplot</span>(<span class="kw">data.frame</span>(res), <span class="kw">aes</span>(<span class="dt">x =</span> res)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb133-13"><a href="distributions.html#cb133-13"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&#39;black&#39;</span>, <span class="dt">fill=</span><span class="st">&#39;#894ae0&#39;</span>, <span class="dt">alpha=</span>.<span class="dv">5</span>, <span class="dt">binwidth =</span> <span class="dv">1</span>) <span class="op">+</span></span>
<span id="cb133-14"><a href="distributions.html#cb133-14"></a><span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span></span>
<span id="cb133-15"><a href="distributions.html#cb133-15"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="kw">mean</span>(res), <span class="dt">lwd=</span><span class="dv">1</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb133-16"><a href="distributions.html#cb133-16"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Mean of each sample&quot;</span>) <span class="op">+</span></span>
<span id="cb133-17"><a href="distributions.html#cb133-17"></a><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Frequency&quot;</span>) <span class="op">+</span></span>
<span id="cb133-18"><a href="distributions.html#cb133-18"></a><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Sampling Distribution of Sample Means for n=30&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-44-1.png" width="672" /></p>
<p>This histogram represents our sampling distribution of sample means when we took samples of size 30 from a uniform distribution. Hopefully you notice that it is approximately normally distributed - even though the original population was uniformally distributed! Let’s calculate the mean and standard deviation of this sampling distribution:</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="distributions.html#cb134-1"></a><span class="kw">mean</span>(res)  <span class="co"># the mean of the sample means is close to 37.5, the population mean</span></span></code></pre></div>
<pre><code>## [1] 37.49964</code></pre>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="distributions.html#cb136-1"></a><span class="kw">sd</span>(res)  <span class="co">#3.996 - this is a lot smaller than the population SD</span></span></code></pre></div>
<pre><code>## [1] 3.995888</code></pre>
<p>The mean of our sampling distribution <span class="math inline">\(\mu_{\overline{x}} = 37.5\)</span> which is again approximately equal to the population mean. The sampling distribution standard deviation <span class="math inline">\(\sigma_{\overline{x}} = 3.99\)</span> which is a lot lower than the original population standard deviation. Because we only took 10,000 samples, these values aren’t exact, but we could have calculated the standard error by taking the population standard deviation and dividing by the square root of n <span class="math inline">\(\Large \sigma_{\overline{x}} = \frac{\sigma}{\sqrt{n}}\)</span> as follows:</p>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="distributions.html#cb138-1"></a><span class="kw">sd</span>(x1)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">30</span>)  <span class="co"># standard error.</span></span></code></pre></div>
<pre><code>## [1] 3.952219</code></pre>
<p>You’ll notice that this calculated value is very close to the one we estimated by running our simulation.</p>
<p><br></p>
<p><strong>Skewed Distributions</strong></p>
<p>We can see that the central limit theorem holds true for skewed distributions also. Here, we have a population of 1 million charity donations. Let’s draw a hisogram of the population distribution and calculate the mean and standard deviation of the population.</p>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="distributions.html#cb140-1"></a><span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb140-2"><a href="distributions.html#cb140-2"></a><span class="co"># e.g. Donations to a charity (in $s)</span></span>
<span id="cb140-3"><a href="distributions.html#cb140-3"></a></span>
<span id="cb140-4"><a href="distributions.html#cb140-4"></a>q &lt;-<span class="st"> </span><span class="kw">rnbinom</span>(<span class="dv">1000000</span>, <span class="dv">5</span>, <span class="fl">.4</span>)</span>
<span id="cb140-5"><a href="distributions.html#cb140-5"></a></span>
<span id="cb140-6"><a href="distributions.html#cb140-6"></a><span class="co"># histogram</span></span>
<span id="cb140-7"><a href="distributions.html#cb140-7"></a><span class="kw">ggplot</span>(<span class="kw">data.frame</span>(q), <span class="kw">aes</span>(<span class="dt">x =</span> q)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb140-8"><a href="distributions.html#cb140-8"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&#39;black&#39;</span>, </span>
<span id="cb140-9"><a href="distributions.html#cb140-9"></a>                 <span class="dt">fill =</span> <span class="st">&quot;#1ad665&quot;</span>, </span>
<span id="cb140-10"><a href="distributions.html#cb140-10"></a>                 <span class="dt">alpha=</span>.<span class="dv">3</span>, </span>
<span id="cb140-11"><a href="distributions.html#cb140-11"></a>                 <span class="dt">binwidth =</span> <span class="dv">1</span>,</span>
<span id="cb140-12"><a href="distributions.html#cb140-12"></a>                 <span class="dt">boundary =</span> <span class="dv">0</span>) <span class="op">+</span></span>
<span id="cb140-13"><a href="distributions.html#cb140-13"></a><span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span></span>
<span id="cb140-14"><a href="distributions.html#cb140-14"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Charity Donation in $&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-47-1.png" width="672" /></p>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="distributions.html#cb141-1"></a><span class="co">### Population Mean</span></span>
<span id="cb141-2"><a href="distributions.html#cb141-2"></a><span class="kw">mean</span>(q)  <span class="co">#7.5</span></span></code></pre></div>
<pre><code>## [1] 7.504368</code></pre>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="distributions.html#cb143-1"></a><span class="kw">sd</span>(q)  <span class="co">#4.33</span></span></code></pre></div>
<pre><code>## [1] 4.331767</code></pre>
<p>It is clear that this population distribution is highly positively skewed. The mean of the population is 7.5 and the standard deviation is 4.33.</p>
<p>In the following code we takes samples of size 30 and calculate the sample mean of each sample. This time, we’ll collect 50,000 samples, just to be a bit different.</p>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb145-1"><a href="distributions.html#cb145-1"></a>results&lt;-<span class="kw">vector</span>(<span class="st">&#39;list&#39;</span>,<span class="dv">50000</span>)</span>
<span id="cb145-2"><a href="distributions.html#cb145-2"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">10000</span>){</span>
<span id="cb145-3"><a href="distributions.html#cb145-3"></a>  results[[i]]  &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">sample</span>(q, <span class="dv">30</span>, <span class="dt">replace =</span> T))  </span>
<span id="cb145-4"><a href="distributions.html#cb145-4"></a>}</span>
<span id="cb145-5"><a href="distributions.html#cb145-5"></a></span>
<span id="cb145-6"><a href="distributions.html#cb145-6"></a>res &lt;-<span class="st"> </span><span class="kw">unlist</span>(results)</span>
<span id="cb145-7"><a href="distributions.html#cb145-7"></a></span>
<span id="cb145-8"><a href="distributions.html#cb145-8"></a></span>
<span id="cb145-9"><a href="distributions.html#cb145-9"></a><span class="co">### Let&#39;s Draw this as a histogram.</span></span>
<span id="cb145-10"><a href="distributions.html#cb145-10"></a></span>
<span id="cb145-11"><a href="distributions.html#cb145-11"></a><span class="kw">ggplot</span>(<span class="kw">data.frame</span>(res), <span class="kw">aes</span>(<span class="dt">x =</span> res)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb145-12"><a href="distributions.html#cb145-12"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&#39;black&#39;</span>, <span class="dt">fill=</span><span class="st">&#39;#31e8d0&#39;</span>, <span class="dt">alpha=</span>.<span class="dv">5</span>, <span class="dt">binwidth =</span> <span class="fl">.1</span>) <span class="op">+</span></span>
<span id="cb145-13"><a href="distributions.html#cb145-13"></a><span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span></span>
<span id="cb145-14"><a href="distributions.html#cb145-14"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="kw">mean</span>(res), <span class="dt">lwd=</span><span class="dv">1</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb145-15"><a href="distributions.html#cb145-15"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Mean of each sample&quot;</span>) <span class="op">+</span></span>
<span id="cb145-16"><a href="distributions.html#cb145-16"></a><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Frequency&quot;</span>) <span class="op">+</span></span>
<span id="cb145-17"><a href="distributions.html#cb145-17"></a><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Sampling Distribution of Sample Means for n=30&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-48-1.png" width="672" /></p>
<p>So, it happened again. This is our sampling distribution of sample means, collected from samples of size 30 from a highly skewed distribution. But once again, the sampling distribution is approximately normally distributed. It might not be perfectly normally distributed, but it is close to being normal. We can calculate the mean and the standard deviation of this sampling distribution:</p>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="distributions.html#cb146-1"></a><span class="kw">mean</span>(res)  <span class="co"># the mean of the sample means is close to 7.5</span></span></code></pre></div>
<pre><code>## [1] 7.504313</code></pre>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="distributions.html#cb148-1"></a><span class="kw">sd</span>(res)  <span class="co">#0.799</span></span></code></pre></div>
<pre><code>## [1] 0.7981555</code></pre>
<p><span class="math inline">\(\mu_{\overline{x}} = 7.5\)</span> which is once again approximately equal to the original population mean. The sampling distribution standard deviation <span class="math inline">\(\sigma_{\overline{x}} = 0.799\)</span>. We could have directly calculated that using the formula for the standard error, n <span class="math inline">\(\Large \sigma_{\overline{x}} = \frac{\sigma}{\sqrt{n}}\)</span>, as we know the original population standard deviation:</p>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb150-1"><a href="distributions.html#cb150-1"></a><span class="kw">sd</span>(q)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">30</span>)  <span class="co"># standard error = 0.791</span></span></code></pre></div>
<pre><code>## [1] 0.7908688</code></pre>
<p>We could keep going with even more types of population distributions. We would find the same thing over and over again. If we take many samples from each population and calculated the sample means of all samples, they would form an approximately normally distribution. This will be especially true for larger samples. This is the basis of the central limit theorem. In the following sections we’ll learn more about what we can do with these sampling distributions.</p>
<p><br><br></p>
</div>
<div id="sampling-distribution-problems" class="section level2">
<h2><span class="header-section-number">7.4</span> Sampling distribution problems</h2>
<p>We can use our knowledge of sampling distributions and z-scores to determine how likely or unlikely we are to observe any one particular sample mean.</p>
<p>Let’s use an example to illustrate this.</p>
<p style="color:blue">
Q. Say the weight of chicken eggs is normally distributed with mean 60g and standard deviation of 3g. What is the probability of getting a batch of a dozen eggs that have a mean of less than 58g ?
</p>
<p>The way to think about these questions is to recognize that we’re dealing with a sampling distribution. We’re really being asked what proportion of the sampling distribution is less than a sample mean of 58g, when your sample size is 12 (a dozen).</p>
<p>First, let’s plot the population of chicken eggs and then the sampling distribution of samples means for a sample size of 12.</p>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb152-1"><a href="distributions.html#cb152-1"></a><span class="kw">set.seed</span>(<span class="dv">1</span>) <span class="co"># so you get the same values as my script</span></span>
<span id="cb152-2"><a href="distributions.html#cb152-2"></a></span>
<span id="cb152-3"><a href="distributions.html#cb152-3"></a></span>
<span id="cb152-4"><a href="distributions.html#cb152-4"></a><span class="co">### First, I&#39;ll make some plots of the &#39;population&#39; and &#39;sampling distribution&#39;</span></span>
<span id="cb152-5"><a href="distributions.html#cb152-5"></a></span>
<span id="cb152-6"><a href="distributions.html#cb152-6"></a></span>
<span id="cb152-7"><a href="distributions.html#cb152-7"></a><span class="co">## Population</span></span>
<span id="cb152-8"><a href="distributions.html#cb152-8"></a>x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1000000</span>, <span class="dt">mean =</span> <span class="dv">60</span>, <span class="dt">sd =</span> <span class="dv">3</span>)</span>
<span id="cb152-9"><a href="distributions.html#cb152-9"></a></span>
<span id="cb152-10"><a href="distributions.html#cb152-10"></a>p1 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">data.frame</span>(x), <span class="kw">aes</span>(<span class="dt">x =</span> x)) <span class="op">+</span></span>
<span id="cb152-11"><a href="distributions.html#cb152-11"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&#39;black&#39;</span>, <span class="dt">fill=</span><span class="st">&#39;mistyrose&#39;</span>, <span class="dt">alpha=</span>.<span class="dv">4</span>)<span class="op">+</span></span>
<span id="cb152-12"><a href="distributions.html#cb152-12"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="dv">60</span>, <span class="dt">lwd=</span><span class="dv">1</span>) <span class="op">+</span></span>
<span id="cb152-13"><a href="distributions.html#cb152-13"></a><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Population of chicken eggs&quot;</span>) <span class="op">+</span></span>
<span id="cb152-14"><a href="distributions.html#cb152-14"></a><span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span></span>
<span id="cb152-15"><a href="distributions.html#cb152-15"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Weight&quot;</span>)</span>
<span id="cb152-16"><a href="distributions.html#cb152-16"></a></span>
<span id="cb152-17"><a href="distributions.html#cb152-17"></a></span>
<span id="cb152-18"><a href="distributions.html#cb152-18"></a><span class="co">## Sampling Distribution of sample means with Sample size of 12 (a dozen).</span></span>
<span id="cb152-19"><a href="distributions.html#cb152-19"></a></span>
<span id="cb152-20"><a href="distributions.html#cb152-20"></a>results&lt;-<span class="kw">vector</span>(<span class="st">&#39;list&#39;</span>,<span class="dv">10000</span>)</span>
<span id="cb152-21"><a href="distributions.html#cb152-21"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">10000</span>){</span>
<span id="cb152-22"><a href="distributions.html#cb152-22"></a>  results[[i]] &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">sample</span>(x, <span class="dv">12</span>, <span class="dt">replace =</span> T))</span>
<span id="cb152-23"><a href="distributions.html#cb152-23"></a>}</span>
<span id="cb152-24"><a href="distributions.html#cb152-24"></a></span>
<span id="cb152-25"><a href="distributions.html#cb152-25"></a>res &lt;-<span class="st"> </span><span class="kw">unlist</span>(results)</span>
<span id="cb152-26"><a href="distributions.html#cb152-26"></a></span>
<span id="cb152-27"><a href="distributions.html#cb152-27"></a>p2 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">data.frame</span>(res), <span class="kw">aes</span>(<span class="dt">x=</span>res)) <span class="op">+</span></span>
<span id="cb152-28"><a href="distributions.html#cb152-28"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&quot;black&quot;</span>, <span class="dt">fill=</span><span class="st">&#39;lightseagreen&#39;</span>, <span class="dt">alpha=</span>.<span class="dv">4</span>)<span class="op">+</span></span>
<span id="cb152-29"><a href="distributions.html#cb152-29"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="kw">mean</span>(res),<span class="dt">lwd=</span><span class="dv">1</span>) <span class="op">+</span></span>
<span id="cb152-30"><a href="distributions.html#cb152-30"></a><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Sampling Distribution of Sample Means&quot;</span>) <span class="op">+</span></span>
<span id="cb152-31"><a href="distributions.html#cb152-31"></a><span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span></span>
<span id="cb152-32"><a href="distributions.html#cb152-32"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;sample mean&quot;</span>)</span>
<span id="cb152-33"><a href="distributions.html#cb152-33"></a></span>
<span id="cb152-34"><a href="distributions.html#cb152-34"></a><span class="kw">library</span>(gridExtra)</span>
<span id="cb152-35"><a href="distributions.html#cb152-35"></a><span class="kw">grid.arrange</span>(p1,p2,<span class="dt">nrow=</span><span class="dv">1</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-51-1.png" width="672" /></p>
<p>What are the mean and standard deviation of this sampling distribution of sample means? Well, <span class="math inline">\(\mu_{\overline{x}} = 60\)</span> because that’s the population mean, and we know the mean of the sample means is approximately the same. We know we can calculate <span class="math inline">\(\sigma_{\overline{x}}\)</span> because we know the population standard deviation <span class="math inline">\(\sigma\)</span>.</p>
<p>Again, the formula is <span class="math inline">\(\Large \sigma_{\overline{x}} = \frac{\sigma}{\sqrt{n}}\)</span>. Therefore, the standard deviation of the sampling distribution is <span class="math inline">\(\sigma_{\overline{x}} = 0.87\)</span>:</p>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb153-1"><a href="distributions.html#cb153-1"></a>sem &lt;-<span class="st"> </span><span class="dv">3</span> <span class="op">/</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="dv">12</span>)</span>
<span id="cb153-2"><a href="distributions.html#cb153-2"></a></span>
<span id="cb153-3"><a href="distributions.html#cb153-3"></a>sem</span></code></pre></div>
<pre><code>## [1] 0.8660254</code></pre>
<p>Now, we’re interested in a sample of 12 that has a sample mean of 58g. Let’s visualize what that looks like on the histogram of the sampling distribution:</p>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb155-1"><a href="distributions.html#cb155-1"></a>p2 <span class="op">+</span><span class="st"> </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="dv">58</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">lwd=</span><span class="dv">1</span>, <span class="dt">color=</span><span class="st">&quot;red&quot;</span>) <span class="op">+</span></span>
<span id="cb155-2"><a href="distributions.html#cb155-2"></a><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Sampling Distribution of Sample Means </span><span class="ch">\n</span><span class="st"> for sample size = 12&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-53-1.png" width="672" /></p>
<p>Because we know the mean and standard deviation of this distribution, we can actually calculate the sample mean of 58g as a z-score. Doing this we find that <span class="math inline">\(z = -2.31\)</span>, which means that a sample mean of 58g is 2.31 standard deviations below the mean.</p>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb156-1"><a href="distributions.html#cb156-1"></a><span class="co"># so, 58g as a z-score is...</span></span>
<span id="cb156-2"><a href="distributions.html#cb156-2"></a></span>
<span id="cb156-3"><a href="distributions.html#cb156-3"></a>z &lt;-<span class="st"> </span>(<span class="dv">58</span> <span class="op">-</span><span class="st"> </span><span class="dv">60</span>) <span class="op">/</span><span class="st"> </span>sem  <span class="co"># -2.31</span></span>
<span id="cb156-4"><a href="distributions.html#cb156-4"></a></span>
<span id="cb156-5"><a href="distributions.html#cb156-5"></a>z</span></code></pre></div>
<pre><code>## [1] -2.309401</code></pre>
<p>The original question asked what probability there was of getting a sample mean of less than 58g. This is basically what area is under the curve of the above sampling distribution to the left of the 58g sample mean. Because we converted that sample mean of 58g to a z-score of -2.31, we can look at that value on a standard normal curve. The area we are iterested in is the filled in area to the left of z = -2.31:</p>
<p><img src="img/chicken.png" /></p>
<p>We can look up this value in R, using the function <code>pnorm</code>.</p>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb158-1"><a href="distributions.html#cb158-1"></a><span class="kw">pnorm</span>(z)  <span class="co"># prob = 0.010</span></span></code></pre></div>
<pre><code>## [1] 0.01046067</code></pre>
<p>So we can see that the probability of getting a sample mean of lower than 58g is <code>p=0.0105</code>.</p>
<p><br><br></p>
</div>
<div id="the-t-distribution" class="section level2">
<h2><span class="header-section-number">7.5</span> The t-distribution</h2>
<p>Another distribution that is important to know about is the t-distribution. Like the normal distribution, this is a symmetrical distribution, but it has slighly fatter tails than the normal distribution.</p>
<p>The t-distribution comes up most commonly in sampling distributions. In particular, although the central limit theorem prescribes that sampling distributions are approximately normal, it is known that often they aren’t approximately normal enough, and instead they follow a t-distribution shape.</p>
<p>An important detail about the t-distribution is that there are actually several t-distributions. There are different t-distributions for different degrees of freedom. These differ slightly in how heavy the tails of the distribution are. The degrees of freedom are usually related to the sample size minus one or two (depending upon the test being employed - see sections <a href="one-sample-inferential-statistics.html#one-sample-t-tests">9.2</a> and @ref(theory-behind-student’s-t-test). The higher the degrees of freedom, the more closely the t-distribution looks like a normal distribution. You can see this in the image below. The standard normal distribution is in red, and the t-distribution is in black. Each panel shows a different t-distribution. As the degrees of freedom increase, the t-distribution essentially becomes the normal distribution. At lower degrees of freedom, there is a lot more difference between the t-distribution and the normal distribution in the tails.</p>
<p><img src="img/t.png" /></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="descriptives.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="confidence-intervals.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
